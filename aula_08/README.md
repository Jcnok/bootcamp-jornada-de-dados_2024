# FunÃ§Ãµes em Python - ETL com Pandas, JSON e Parquet

Para realizar uma ETL (Extract, Transform, Load) simples utilizando Python e a biblioteca Pandas, vamos seguir os seguintes passos:

Extract: Ler os dados de um arquivo JSON.

Transform: Concatenar os dados extraÃ­dos em um Ãºnico DataFrame e aplicar uma transformaÃ§Ã£o. A transformaÃ§Ã£o especÃ­fica dependerÃ¡ dos dados, mas vamos assumir uma operaÃ§Ã£o simples como um exemplo.

Load: Salvar o DataFrame resultante em um arquivo CSV ou PARQUET.

## Selecionando a raiz do projeto:


```python
import os
os.getcwd()
os.chdir('/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08')
os.getcwd()
```




    '/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08'



## Loguru: Simplificando o Registro em Python


O Loguru Ã© uma biblioteca de registro (logging) para Python que simplifica bastante o processo de registro de mensagens de registro (logs) em aplicativos Python. Ele oferece uma API fÃ¡cil de usar e poderosa para configurar e gerenciar logs em seus projetos.

### Principais CaracterÃ­sticas

1. **API Simples**: O Loguru oferece uma API muito simples e intuitiva para registro de mensagens. VocÃª pode facilmente configurar o registro com apenas algumas linhas de cÃ³digo.

2. **NÃ­veis de Log PersonalizÃ¡veis**: Ele fornece vÃ¡rios nÃ­veis de log predefinidos (por exemplo, DEBUG, INFO, WARNING, ERROR, etc.) e tambÃ©m permite a definiÃ§Ã£o de nÃ­veis de log personalizados conforme necessÃ¡rio.

3. **FormataÃ§Ã£o FlexÃ­vel**: VocÃª pode personalizar facilmente o formato das mensagens de log de acordo com suas necessidades. O Loguru oferece suporte a formataÃ§Ã£o de mensagem flexÃ­vel e extensÃ­vel.

4. **Suporte a Threads e Processos**: Loguru lida automaticamente com problemas de concorrÃªncia em aplicativos que usam vÃ¡rias threads ou processos, garantindo que as mensagens de log sejam registradas corretamente e sem conflitos.

5. **IntegraÃ§Ã£o com Outras Ferramentas**: Ele se integra facilmente com outras ferramentas e bibliotecas, como Flask, Django, e outras ferramentas populares de registro em Python.

### ConclusÃ£o

O Loguru simplifica o processo de registro de mensagens de log em aplicativos Python, oferecendo uma API fÃ¡cil de usar, flexibilidade na formataÃ§Ã£o de mensagens e uma sÃ©rie de recursos Ãºteis para gerenciamento eficaz de logs. Ã‰ uma escolha popular entre os desenvolvedores Python devido Ã  sua simplicidade e poder.


### O que Ã© Logging?

Logging Ã© o processo de gravar mensagens que documentam os eventos que ocorrem durante a execuÃ§Ã£o de um software. Essas mensagens podem indicar progresso da execuÃ§Ã£o, falhas, erros, ou outras informaÃ§Ãµes Ãºteis. O logging Ã© crucial para desenvolvimento e manutenÃ§Ã£o de software, pois permite aos desenvolvedores e administradores de sistema entender o que o aplicativo estÃ¡ fazendo, diagnosticar problemas e monitorar o desempenho em produÃ§Ã£o.


### InstalaÃ§Ã£o:


```python
!poetry add loguru -q
```

### Como usar:

* **ConfiguraÃ§Ã£o BÃ¡sica e Registro de Mensagens Simples:**


```python
from loguru import logger

# ConfiguraÃ§Ã£o bÃ¡sica
logger.add("log/app.log", rotation="5 MB", level="WARNING")

# Exemplos de registro de mensagens
logger.debug("Esta Ã© uma mensagem de depuraÃ§Ã£o")
logger.info("Esta Ã© uma mensagem informativa")
logger.warning("Esta Ã© uma mensagem de aviso")
logger.error("Esta Ã© uma mensagem de erro")
logger.critical("Esta Ã© uma mensagem crÃ­tica")

```

![img](./img/loguru_basic.png)

* **Agora vamos acessar o arquivo app.log e conferir que ele sÃ³ salvou os logs de level "WARNING".**


```python
# %load log/app.log
2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta Ã© uma mensagem de aviso
2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta Ã© uma mensagem de erro
2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta Ã© uma mensagem crÃ­tica

```

* **Veja que o level "WARNING" nÃ£o salva os logs do tipo 'INFO' e 'DEBUB'.**
* **Assim podemos configurar os nÃ­veis de logs conforme a necessidade.**

### PersonalizaÃ§Ã£o dos logs.

* **Personalizando o formato das mensagens:**


```python
from loguru import logger

# ConfiguraÃ§Ã£o com formato personalizado
logger.add("log/app.log", format="{time} - {level} - {message}", level="INFO")

# Exemplo de registro de mensagem com contexto
logger.info("UsuÃ¡rio {user} fez login", user="Julio Okuda")
```

![img](./img/personalize_loguru.png)

* **Acessando o conteÃºdo do arquivo app.log:**


```python
# %load log/app.log
2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta Ã© uma mensagem de aviso
2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta Ã© uma mensagem de erro
2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta Ã© uma mensagem crÃ­tica
2024-04-09T01:20:43.014364-0300 - INFO - UsuÃ¡rio Julio Okuda fez login

```

* **Tratamento de exceÃ§Ãµes**


```python
from loguru import logger

try:
    # Algum cÃ³digo que pode gerar uma exceÃ§Ã£o
    resultado = 1 / 0
except Exception as e:
    # Registro da exceÃ§Ã£o com o mÃ©todo exception()
    logger.exception("Ocorreu um erro inesperado: {exception}", exception=str(e))

```

![img](./img/exception.png)

Usando logger.exception(), Loguru automaticamente captura e loga o traceback da exceÃ§Ã£o, o que Ã© extremamente Ãºtil para diagnÃ³stico de erros.

* **Vamos criar um decorador utilizando o Loguru para adicionar automaticamente logs a qualquer funÃ§Ã£o Python. Isso nos permite registrar automaticamente quando uma funÃ§Ã£o Ã© chamada e quando ela termina, junto com qualquer informaÃ§Ã£o relevante, como argumentos da funÃ§Ã£o e o resultado retornado (ou exceÃ§Ã£o lanÃ§ada).**

* **Agora, vamos ao cÃ³digo do decorador:**


```python
%%writefile src/utils/log_decorator.py
# decorator para registro de logs
from loguru import logger

def log_decorator(func):
    """
    Decorador para registro de chamadas de funÃ§Ã£o com o Loguru.

    Args:
        func (callable): FunÃ§Ã£o a ser decorada.

    Returns:
        callable: FunÃ§Ã£o decorada.
    """
    def wrapper(*args, **kwargs):
        """
        FunÃ§Ã£o interna que envolve a funÃ§Ã£o original e realiza o registro.

        Args:
            *args: Argumentos posicionais passados para a funÃ§Ã£o.
            **kwargs: Argumentos de palavras-chave passados para a funÃ§Ã£o.

        Returns:
            Qualquer: Resultado da funÃ§Ã£o original.

        Raises:
            Exception: Se a funÃ§Ã£o original lanÃ§ar uma exceÃ§Ã£o.
        """
        # Registra a chamada da funÃ§Ã£o com os argumentos e palavras-chave
        logger.info(f"Chamando '{func.__name__}' com {args} e {kwargs}")

        try:
            # Chama a funÃ§Ã£o original e captura o resultado
            result = func(*args, **kwargs)
            # Registra o retorno da funÃ§Ã£o
            logger.info(f"'{func.__name__}' retornou {result}")
            return result
        except Exception as e:
            # Registra a exceÃ§Ã£o se a funÃ§Ã£o original lanÃ§ar uma exceÃ§Ã£o
            logger.exception(f"'{func.__name__}' lanÃ§ou uma exceÃ§Ã£o: {e}")
            # Propaga a exceÃ§Ã£o para cima na cadeia de chamadas
            raise

    return wrapper

```

    Writing src/utils/log_decorator.py


### Uso e ExecuÃ§Ã£o do Decorador de Registro com Loguru

O decorador `log_decorator` Ã© uma ferramenta Ãºtil para registrar chamadas de funÃ§Ã£o em aplicativos Python usando a biblioteca Loguru. Este decorador pode ser aplicado a qualquer funÃ§Ã£o para automatizar o registro de suas chamadas e resultados.

#### Como Usar o Decorador

Para usar o decorador `log_decorator`, siga estas etapas:

1. **Importe o Decorador**: Importe o decorador `log_decorator` de onde ele estiver definido no seu cÃ³digo.

2. **Aplique o Decorador**: Aplique o decorador `log_decorator` Ã  funÃ§Ã£o que deseja registrar. Por exemplo:

    ```python
    @log_decorator
    def minha_funcao(parametro):
        # Corpo da funÃ§Ã£o
        pass
    ```

    Isso irÃ¡ decorar a funÃ§Ã£o `minha_funcao` com o decorador de registro, permitindo que todas as suas chamadas sejam registradas automaticamente.

#### ExecuÃ§Ã£o do Decorador

Quando uma funÃ§Ã£o decorada com `log_decorator` Ã© chamada, o decorador entra em aÃ§Ã£o:

1. **Registro de Chamada**: O decorador registra a chamada da funÃ§Ã£o, incluindo os argumentos passados.

2. **ExecuÃ§Ã£o da FunÃ§Ã£o Original**: O decorador chama a funÃ§Ã£o original com os argumentos fornecidos.

3. **Registro de Resultado**: Se a funÃ§Ã£o for executada com sucesso, o decorador registra o resultado retornado.

4. **GestÃ£o de ExceÃ§Ãµes**: Se a funÃ§Ã£o lanÃ§ar uma exceÃ§Ã£o durante a execuÃ§Ã£o, o decorador registra a exceÃ§Ã£o e a propaga para cima na cadeia de chamadas.


### Como Utilizar o Decorador

Agora, veja como aplicar o `log_decorator` a uma funÃ§Ã£o:


```python
#primeir devemos imporar o decorador
from src.utils.log_decorator import log_decorator
@log_decorator
def soma(a, b):
    return a + b
```

* **Veja um exemplo de uma funÃ§Ã£o bem simples usando o decorador que acabamos de criar**:


```python
# ExecuÃ§Ã£o da funÃ§Ã£o soma
soma(5,3)
```

![decorator_soma](./img/decorator_soma.png)

* **O decorator encapsulou a funÃ§Ã£o e jÃ¡ imprimiu os logs do tipo INFO.**
* **SerÃ¡ que o log foi registrado no app.log?**
  * Como havia configurado o level para "INFO" esse log, deve estar registrado no arquivo vamos conferir.


```python
# %load log/app.log
2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta Ã© uma mensagem de aviso
2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta Ã© uma mensagem de erro
2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta Ã© uma mensagem crÃ­tica
2024-04-09T01:20:43.014364-0300 - INFO - UsuÃ¡rio Julio Okuda fez login
2024-04-09T01:54:01.939913-0300 - INFO - Chamando 'soma' com (5, 3) e {}
2024-04-09T01:54:01.946493-0300 - INFO - 'soma' retornou 8

```

* **Realizando um teste de falha**:


```python
# realizando uma soma que irÃ¡ falhar
soma(3, "3")
```

* **Vamos acessar o arquivo de log**:


```python
# %load log/app.log
2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta Ã© uma mensagem de aviso
2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta Ã© uma mensagem de erro
2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta Ã© uma mensagem crÃ­tica
2024-04-09T01:20:43.014364-0300 - INFO - UsuÃ¡rio Julio Okuda fez login
2024-04-09T01:54:01.939913-0300 - INFO - Chamando 'soma' com (5, 3) e {}
2024-04-09T01:54:01.946493-0300 - INFO - 'soma' retornou 8
2024-04-09T02:04:21.395570-0300 - INFO - Chamando 'soma' com (3, '3') e {}
2024-04-09 02:04:21.402 | ERROR    | src.utils.log_decorator:wrapper:39 - 'soma' lanÃ§ou uma exceÃ§Ã£o: unsupported operand type(s) for +: 'int' and 'str'
Traceback (most recent call last):

  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           â”‚         â”‚     â”” {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\n\nThis is separate from the ipykernel pack...
           â”‚         â”” <code object <module> at 0x7f795a3533c0, file "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...
           â”” <function _run_code at 0x7f795a35fac0>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         â”‚     â”” {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\n\nThis is separate from the ipykernel pack...
         â”” <code object <module> at 0x7f795a3533c0, file "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel_launcher.py", line 18, in <module>
    app.launch_new_instance()
    â”‚   â”” <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>
    â”” <module 'ipykernel.kernelapp' from '/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/i...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
    â”‚   â”” <function IPKernelApp.start at 0x7f79576943a0>
    â”” <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py", line 739, in start
    self.io_loop.start()
    â”‚    â”‚       â”” <function BaseAsyncIOLoop.start at 0x7f7957694ee0>
    â”‚    â”” <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>
    â”” <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py", line 205, in start
    self.asyncio_loop.run_forever()
    â”‚    â”‚            â”” <function BaseEventLoop.run_forever at 0x7f7959232f80>
    â”‚    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
    â”” <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py", line 603, in run_forever
    self._run_once()
    â”‚    â”” <function BaseEventLoop._run_once at 0x7f7959234af0>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py", line 1909, in _run_once
    handle._run()
    â”‚      â”” <function Handle._run at 0x7f795994c160>
    â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
    â”‚    â”‚            â”‚    â”‚           â”‚    â”” <member '_args' of 'Handle' objects>
    â”‚    â”‚            â”‚    â”‚           â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
    â”‚    â”‚            â”‚    â”” <member '_callback' of 'Handle' objects>
    â”‚    â”‚            â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
    â”‚    â”” <member '_context' of 'Handle' objects>
    â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 545, in dispatch_queue
    await self.process_one()
          â”‚    â”” <function Kernel.process_one at 0x7f7957ab2320>
          â”” <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 534, in process_one
    await dispatch(*args)
          â”‚         â”” ([<zmq.sugar.frame.Frame object at 0x7f79444b6fb0>, <zmq.sugar.frame.Frame object at 0x7f7944451430>, <zmq.sugar.frame.Frame ...
          â”” <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 437, in dispatch_shell
    await result
          â”” <coroutine object IPythonKernel.execute_request at 0x7f7944407220>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py", line 359, in execute_request
    await super().execute_request(stream, ident, parent)
                                  â”‚       â”‚      â”” {'header': {'date': datetime.datetime(2024, 4, 9, 5, 4, 21, 389000, tzinfo=tzutc()), 'msg_id': '08c451f7-fbb9-4ff8-979a-5a9b4...
                                  â”‚       â”” [b'4455ded5-0c77-428d-affa-44648e506000']
                                  â”” <zmq.eventloop.zmqstream.ZMQStream object at 0x7f795768ff70>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 778, in execute_request
    reply_content = await reply_content
                          â”” <coroutine object IPythonKernel.do_execute at 0x7f7944405fc0>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py", line 446, in do_execute
    res = shell.run_cell(
          â”‚     â”” <function ZMQInteractiveShell.run_cell at 0x7f7957675a20>
          â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py", line 549, in run_cell
    return super().run_cell(*args, **kwargs)
                             â”‚       â”” {'store_history': True, 'silent': False, 'cell_id': '07b7bc1a-fc26-49aa-adf6-59049db07319'}
                             â”” ('# realizando uma soma que irÃ¡ falhar \nsoma(3, "3")',)
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3075, in run_cell
    result = self._run_cell(
             â”‚    â”” <function InteractiveShell._run_cell at 0x7f795861e560>
             â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3130, in _run_cell
    result = runner(coro)
             â”‚      â”” <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>
             â”” <function _pseudo_sync_runner at 0x7f795860dea0>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py", line 129, in _pseudo_sync_runner
    coro.send(None)
    â”‚    â”” <method 'send' of 'coroutine' objects>
    â”” <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3334, in run_cell_async
    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
                       â”‚    â”‚             â”‚        â”‚     â”” '/tmp/ipykernel_15051/3086203311.py'
                       â”‚    â”‚             â”‚        â”” [<ast.Expr object at 0x7f7944244dc0>]
                       â”‚    â”‚             â”” <ast.Module object at 0x7f7944245db0>
                       â”‚    â”” <function InteractiveShell.run_ast_nodes at 0x7f795861e830>
                       â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3517, in run_ast_nodes
    if await self.run_code(code, result, async_=asy):
             â”‚    â”‚        â”‚     â”‚              â”” False
             â”‚    â”‚        â”‚     â”” <ExecutionResult object at 7f79442447f0, execution_count=21 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...
             â”‚    â”‚        â”” <code object <module> at 0x7f79442ccc90, file "/tmp/ipykernel_15051/3086203311.py", line 1>
             â”‚    â”” <function InteractiveShell.run_code at 0x7f795861e8c0>
             â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3577, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
         â”‚         â”‚    â”‚               â”‚    â”” {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...
         â”‚         â”‚    â”‚               â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
         â”‚         â”‚    â”” <property object at 0x7f7958603b00>
         â”‚         â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
         â”” <code object <module> at 0x7f79442ccc90, file "/tmp/ipykernel_15051/3086203311.py", line 1>

  File "/tmp/ipykernel_15051/3086203311.py", line 2, in <module>
    soma(3, "3")
    â”” <function log_decorator.<locals>.wrapper at 0x7f7944922830>

> File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/log_decorator.py", line 33, in wrapper
    result = func(*args, **kwargs)
             â”‚     â”‚       â”” {}
             â”‚     â”” (3, '3')
             â”” <function soma at 0x7f7944921750>

  File "/tmp/ipykernel_15051/1321141747.py", line 5, in soma
    return a + b
           â”‚   â”” '3'
           â”” 3

TypeError: unsupported operand type(s) for +: 'int' and 'str'
2024-04-09T02:04:21.402181-0300 - ERROR - 'soma' lanÃ§ou uma exceÃ§Ã£o: unsupported operand type(s) for +: 'int' and 'str'
Traceback (most recent call last):

  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           â”‚         â”‚     â”” {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\n\nThis is separate from the ipykernel pack...
           â”‚         â”” <code object <module> at 0x7f795a3533c0, file "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...
           â”” <function _run_code at 0x7f795a35fac0>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         â”‚     â”” {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\n\nThis is separate from the ipykernel pack...
         â”” <code object <module> at 0x7f795a3533c0, file "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel_launcher.py", line 18, in <module>
    app.launch_new_instance()
    â”‚   â”” <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>
    â”” <module 'ipykernel.kernelapp' from '/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/i...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
    â”‚   â”” <function IPKernelApp.start at 0x7f79576943a0>
    â”” <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py", line 739, in start
    self.io_loop.start()
    â”‚    â”‚       â”” <function BaseAsyncIOLoop.start at 0x7f7957694ee0>
    â”‚    â”” <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>
    â”” <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py", line 205, in start
    self.asyncio_loop.run_forever()
    â”‚    â”‚            â”” <function BaseEventLoop.run_forever at 0x7f7959232f80>
    â”‚    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
    â”” <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py", line 603, in run_forever
    self._run_once()
    â”‚    â”” <function BaseEventLoop._run_once at 0x7f7959234af0>
    â”” <_UnixSelectorEventLoop running=True closed=False debug=False>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py", line 1909, in _run_once
    handle._run()
    â”‚      â”” <function Handle._run at 0x7f795994c160>
    â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
  File "/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
    â”‚    â”‚            â”‚    â”‚           â”‚    â”” <member '_args' of 'Handle' objects>
    â”‚    â”‚            â”‚    â”‚           â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
    â”‚    â”‚            â”‚    â”” <member '_callback' of 'Handle' objects>
    â”‚    â”‚            â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
    â”‚    â”” <member '_context' of 'Handle' objects>
    â”” <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 545, in dispatch_queue
    await self.process_one()
          â”‚    â”” <function Kernel.process_one at 0x7f7957ab2320>
          â”” <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 534, in process_one
    await dispatch(*args)
          â”‚         â”” ([<zmq.sugar.frame.Frame object at 0x7f79444b6fb0>, <zmq.sugar.frame.Frame object at 0x7f7944451430>, <zmq.sugar.frame.Frame ...
          â”” <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 437, in dispatch_shell
    await result
          â”” <coroutine object IPythonKernel.execute_request at 0x7f7944407220>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py", line 359, in execute_request
    await super().execute_request(stream, ident, parent)
                                  â”‚       â”‚      â”” {'header': {'date': datetime.datetime(2024, 4, 9, 5, 4, 21, 389000, tzinfo=tzutc()), 'msg_id': '08c451f7-fbb9-4ff8-979a-5a9b4...
                                  â”‚       â”” [b'4455ded5-0c77-428d-affa-44648e506000']
                                  â”” <zmq.eventloop.zmqstream.ZMQStream object at 0x7f795768ff70>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py", line 778, in execute_request
    reply_content = await reply_content
                          â”” <coroutine object IPythonKernel.do_execute at 0x7f7944405fc0>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py", line 446, in do_execute
    res = shell.run_cell(
          â”‚     â”” <function ZMQInteractiveShell.run_cell at 0x7f7957675a20>
          â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py", line 549, in run_cell
    return super().run_cell(*args, **kwargs)
                             â”‚       â”” {'store_history': True, 'silent': False, 'cell_id': '07b7bc1a-fc26-49aa-adf6-59049db07319'}
                             â”” ('# realizando uma soma que irÃ¡ falhar \nsoma(3, "3")',)
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3075, in run_cell
    result = self._run_cell(
             â”‚    â”” <function InteractiveShell._run_cell at 0x7f795861e560>
             â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3130, in _run_cell
    result = runner(coro)
             â”‚      â”” <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>
             â”” <function _pseudo_sync_runner at 0x7f795860dea0>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py", line 129, in _pseudo_sync_runner
    coro.send(None)
    â”‚    â”” <method 'send' of 'coroutine' objects>
    â”” <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3334, in run_cell_async
    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
                       â”‚    â”‚             â”‚        â”‚     â”” '/tmp/ipykernel_15051/3086203311.py'
                       â”‚    â”‚             â”‚        â”” [<ast.Expr object at 0x7f7944244dc0>]
                       â”‚    â”‚             â”” <ast.Module object at 0x7f7944245db0>
                       â”‚    â”” <function InteractiveShell.run_ast_nodes at 0x7f795861e830>
                       â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3517, in run_ast_nodes
    if await self.run_code(code, result, async_=asy):
             â”‚    â”‚        â”‚     â”‚              â”” False
             â”‚    â”‚        â”‚     â”” <ExecutionResult object at 7f79442447f0, execution_count=21 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...
             â”‚    â”‚        â”” <code object <module> at 0x7f79442ccc90, file "/tmp/ipykernel_15051/3086203311.py", line 1>
             â”‚    â”” <function InteractiveShell.run_code at 0x7f795861e8c0>
             â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py", line 3577, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
         â”‚         â”‚    â”‚               â”‚    â”” {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...
         â”‚         â”‚    â”‚               â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
         â”‚         â”‚    â”” <property object at 0x7f7958603b00>
         â”‚         â”” <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>
         â”” <code object <module> at 0x7f79442ccc90, file "/tmp/ipykernel_15051/3086203311.py", line 1>

  File "/tmp/ipykernel_15051/3086203311.py", line 2, in <module>
    soma(3, "3")
    â”” <function log_decorator.<locals>.wrapper at 0x7f7944922830>

> File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/log_decorator.py", line 33, in wrapper
    result = func(*args, **kwargs)
             â”‚     â”‚       â”” {}
             â”‚     â”” (3, '3')
             â”” <function soma at 0x7f7944921750>

  File "/tmp/ipykernel_15051/1321141747.py", line 5, in soma
    return a + b
           â”‚   â”” '3'
           â”” 3

TypeError: unsupported operand type(s) for +: 'int' and 'str'

```

* **Veja que ele salvou o erro com todos os detalhes, por isso determinar o nÃ­vel de log de acordo com a necessidade Ã© importante, pois nÃ£o seria interessante salvar todo tipo de log, sÃ³ iria poluir o registro dificultando a resoluÃ§Ã£o do problema.**


```python
# teste em caso de falha
```

Ao decorar as funÃ§Ãµes `soma` e `falha` com `@log_decorator`, automaticamente logamos a entrada e saÃ­da (ou exceÃ§Ã£o) dessas funÃ§Ãµes sem alterar o corpo delas. Isso Ã© especialmente Ãºtil para debugar, monitorar a performance de aplicaÃ§Ãµes ou simplesmente manter um registro de quais funÃ§Ãµes estÃ£o sendo chamadas e com quais argumentos.



#### BenefÃ­cios do Uso de Decoradores com Loguru


O uso de decoradores em conjunto com o Loguru fornece uma abordagem elegante e poderosa para adicionar logs a aplicaÃ§Ãµes Python. Sem a necessidade de modificar o corpo da funÃ§Ã£o, podemos facilmente adicionar funcionalidades de logging, o que torna o cÃ³digo mais limpo, mantÃ©m a separaÃ§Ã£o de preocupaÃ§Ãµes e facilita a manutenÃ§Ã£o e o debugging.

AlÃ©m disso, ao centralizar a lÃ³gica de logging no decorador, promovemos a reutilizaÃ§Ã£o de cÃ³digo e garantimos uma forma consistente de logar informaÃ§Ãµes atravÃ©s de diferentes partes de uma aplicaÃ§Ã£o.


### ConclusÃ£o


O Loguru oferece uma abordagem moderna e conveniente para logging em Python, simplificando muitos aspectos que requerem configuraÃ§Ã£o manual detalhada com o mÃ³dulo de logging padrÃ£o do Python. Seja para desenvolvimento, depuraÃ§Ã£o ou produÃ§Ã£o, adicionar logging ao seu aplicativo com Loguru pode melhorar significativamente a visibilidade e a capacidade de diagnÃ³stico do seu cÃ³digo.


# Desafio:
* **Aplicar decorador de Log, Timer e Qualidade em nossa ETL**

![img](./img/pic_05.png)


```python
%%writefile src/etl.py
# Desafio ETL
import os
from typing import List
import pandas as pd
import glob

def ler_arquivos_json(path_origin: str) -> pd.DataFrame:
    caminho_arquivos = os.path.join(path_origin, '*.json')
    arquivos_json = glob.glob(caminho_arquivos)
    if not arquivos_json:
        raise ValueError("Nenhum arquivo JSON encontrado na pasta especificada.")
    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]
    return pd.concat(dfs, ignore_index=True)

def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    df['Receita'] = df['Quantidade'] * df['Venda']
    return df

def carregar_dataframe(df: pd.DataFrame, path_to_save: str, format_to_save: List[str]) -> None:
    for formato in format_to_save:
        if formato.lower() == 'csv':
            caminho_salvar_csv = path_to_save + '.csv'
            df.to_csv(caminho_salvar_csv, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_csv}'")
        elif formato.lower() == 'parquet':
            caminho_salvar_parquet = path_to_save + '.parquet'
            df.to_parquet(caminho_salvar_parquet, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_parquet}'")
        else:
            raise ValueError("Formato especificado nÃ£o suportado. Use 'csv' ou 'parquet'.")

def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:
    df = ler_arquivos_json(path_origin)
    df = transformar_dataframe(df)
    carregar_dataframe(df, path_to_save, format_to_save)

if __name__ == "__main__":
    path_to_save = 'data/process/dados_processados'
    path_origin = 'data/'
    format_to_save = ['csv','parquet']  # ou 'parquet'

    pipeline(path_origin, path_to_save, format_to_save)

```

    Writing src/etl.py



```python
!python src/etl.py
```

    DataFrame salvo em 'data/process/dados_processados.csv'
    DataFrame salvo em 'data/process/dados_processados.parquet'


## ResoluÃ§Ã£o do desafio:

* **Decorators:**
* [x] Decorator para computar o tempo de execuÃ§Ã£o;
* [x] Decorator para Qualidade de dados usando o pandera ou pydantic
* [x] Decorator para logs com loguru.

### Decorator para computar o tempo.:


```python
%%writefile src/utils/timer_decorator.py
# Decorator para computar o tempo de execuÃ§Ã£o:
from datetime import datetime
from loguru import logger
from functools import wraps

def timer(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = datetime.now()
        result = func(*args, **kwargs)
        end_time = datetime.now()
        elapsed_time = end_time - start_time
        logger.info(f"Function '{func.__name__}' executed in {elapsed_time}")
        return result
    return wrapper
```

    Overwriting src/utils/timer_decorator.py


* **Incorporando o decorator timer ao script de etl**:


```python
%%writefile src/etl.py
# Desafio ETL
import glob
import os
from typing import List
#importando os decorators
from utils.timer_decorator import timer

import pandas as pd


def ler_arquivos_json(path_origin: str) -> pd.DataFrame:
    caminho_arquivos = os.path.join(path_origin, "*.json")
    arquivos_json = glob.glob(caminho_arquivos)
    if not arquivos_json:
        raise ValueError("Nenhum arquivo JSON encontrado na pasta especificada.")
    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]
    return pd.concat(dfs, ignore_index=True)


def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    df["Receita"] = df["Quantidade"] * df["Venda"]
    return df


def carregar_dataframe(
    df: pd.DataFrame, path_to_save: str, format_to_save: List[str]
) -> None:
    for formato in format_to_save:
        if formato.lower() == "csv":
            caminho_salvar_csv = path_to_save + ".csv"
            df.to_csv(caminho_salvar_csv, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_csv}'")
        elif formato.lower() == "parquet":
            caminho_salvar_parquet = path_to_save + ".parquet"
            df.to_parquet(caminho_salvar_parquet, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_parquet}'")
        else:
            raise ValueError(
                "Formato especificado nÃ£o suportado. Use 'csv' ou 'parquet'."
            )

@timer
def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:
    df = ler_arquivos_json(path_origin)
    df = transformar_dataframe(df)
    carregar_dataframe(df, path_to_save, format_to_save)


if __name__ == "__main__":
    path_to_save = "data/process/dados_processados"
    path_origin = "data/"
    format_to_save = ["csv", "parquet"]  # ou 'parquet'

    pipeline(path_origin, path_to_save, format_to_save)

```

    Overwriting src/etl.py


* **ExecuÃ§Ã£o da pipeline com o decorator de timer**:


```python
!python src/pipeline.py
```

    DataFrame salvo em 'data/process/dados_processados.csv'
    DataFrame salvo em 'data/process/dados_processados.parquet'
    [32m2024-04-09 23:10:35.321[0m | [1mINFO    [0m | [36mutils.timer_decorator[0m:[36mwrapper[0m:[36m13[0m - [1mFunction 'pipeline' executed in 0:00:00.028769[0m


### Decorator para computar o log com loguru:


```python
%%writefile src/utils/log_decorator.py
# decorator para registro de logs
from loguru import logger
from sys import stderr
from functools import wraps

# Removendo os handlers existentes para evitar duplicaÃ§Ã£o
logger.remove()

# ConfiguraÃ§Ã£o do logger para stderr
logger.add(
                sink=stderr,
                format="{time} <r>{level}</r> <g>{message}</g> {file}",
                level="INFO"
            )

# ConfiguraÃ§Ã£o do logger para arquivo de log
logger.add(
                "log/app.log",
                format="{time} {level} {message} {file}",
                level="INFO"
            )

def log_decorator(func):
    """
    Decorador para registro de chamadas de funÃ§Ã£o com o Loguru.

    Args:
        func (callable): FunÃ§Ã£o a ser decorada.

    Returns:
        callable: FunÃ§Ã£o decorada.
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        """
        FunÃ§Ã£o interna que envolve a funÃ§Ã£o original e realiza o registro.

        Args:
            *args: Argumentos posicionais passados para a funÃ§Ã£o.
            **kwargs: Argumentos de palavras-chave passados para a funÃ§Ã£o.

        Returns:
            Qualquer: Resultado da funÃ§Ã£o original.

        Raises:
            Exception: Se a funÃ§Ã£o original lanÃ§ar uma exceÃ§Ã£o.
        """
        # Registra a chamada da funÃ§Ã£o com os argumentos e palavras-chave
        logger.info(f"Chamando '{func.__name__}' com {args} e {kwargs}")

        try:
            # Chama a funÃ§Ã£o original e captura o resultado
            result = func(*args, **kwargs)
            # Registra o retorno da funÃ§Ã£o
            logger.info(f"'{func.__name__}' retornou {result}")
            return result
        except Exception as e:
            # Registra a exceÃ§Ã£o se a funÃ§Ã£o original lanÃ§ar uma exceÃ§Ã£o
            logger.exception(f"'{func.__name__}' lanÃ§ou uma exceÃ§Ã£o: {e}")
            # Propaga a exceÃ§Ã£o para cima na cadeia de chamadas
            raise

    return wrapper
```

    Overwriting src/utils/log_decorator.py


* **Incorporando o decorator timer ao script de etl**:


```python
%%writefile src/etl.py
# Desafio ETL
import glob
import os
from typing import List
#importando os decorators
from utils.timer_decorator import timer
from utils.log_decorator import log_decorator
import pandas as pd


def ler_arquivos_json(path_origin: str) -> pd.DataFrame:
    caminho_arquivos = os.path.join(path_origin, "*.json")
    arquivos_json = glob.glob(caminho_arquivos)
    if not arquivos_json:
        raise ValueError("Nenhum arquivo JSON encontrado na pasta especificada.")
    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]
    return pd.concat(dfs, ignore_index=True)


def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    df["Receita"] = df["Quantidade"] * df["Venda"]
    return df


def carregar_dataframe(
    df: pd.DataFrame, path_to_save: str, format_to_save: List[str]
) -> None:
    for formato in format_to_save:
        if formato.lower() == "csv":
            caminho_salvar_csv = path_to_save + ".csv"
            df.to_csv(caminho_salvar_csv, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_csv}'")
        elif formato.lower() == "parquet":
            caminho_salvar_parquet = path_to_save + ".parquet"
            df.to_parquet(caminho_salvar_parquet, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_parquet}'")
        else:
            raise ValueError(
                "Formato especificado nÃ£o suportado. Use 'csv' ou 'parquet'."
            )
@log_decorator
@timer
def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:
    df = ler_arquivos_json(path_origin)
    df = transformar_dataframe(df)
    carregar_dataframe(df, path_to_save, format_to_save)


if __name__ == "__main__":
    path_to_save = "data/process/dados_processados"
    path_origin = "data/"
    format_to_save = ["csv", "parquet"]  # ou 'parquet'

    pipeline(path_origin, path_to_save, format_to_save)

```

    Overwriting src/etl.py


* **ExecuÃ§Ã£o da pipeline com o decorator**:


```python
!python src/pipeline.py
```

    2024-04-09T23:21:24.577546-0300 [31mINFO[0m [32mChamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {}[0m log_decorator.py
    DataFrame salvo em 'data/process/dados_processados.csv'
    DataFrame salvo em 'data/process/dados_processados.parquet'
    2024-04-09T23:21:24.608103-0300 [31mINFO[0m [32mFunction 'pipeline' executed in 0:00:00.030056[0m timer_decorator.py
    2024-04-09T23:21:24.608452-0300 [31mINFO[0m [32m'pipeline' retornou None[0m log_decorator.py


* **Tanto o decorator de timer quanto o de log estÃ£o funcionando**.

### Decorator para computar o log com pandera:

* **InstaÃ§Ã£o da lib pandera:**


```python
!poetry add pandera -q
```

#### Pandera: Validando e Limpeza de Dados em Dataframes

Pandera Ã© uma biblioteca Python usada para validaÃ§Ã£o e limpeza de dados em dataframes, inspirada na biblioteca Pydantic e no esquema JSON Schema. Ele oferece uma maneira simples e declarativa de definir esquemas para validar dados tabulares, como dataframes Pandas.

##### Principais CaracterÃ­sticas:

1. **Declarativo e Expressivo**: Pandera permite que vocÃª defina esquemas de validaÃ§Ã£o de dados de forma declarativa e expressiva, facilitando a compreensÃ£o e manutenÃ§Ã£o das regras de validaÃ§Ã£o.

2. **IntegraÃ§Ã£o com Pandas**: ConstruÃ­da em cima do Pandas, a Pandera Ã© totalmente integrada com a estrutura de dados de dataframe do Pandas, facilitando a aplicaÃ§Ã£o da validaÃ§Ã£o de dados aos seus dataframes existentes.

3. **ValidaÃ§Ã£o ExtensÃ­vel**: Oferece uma ampla gama de validaÃ§Ãµes embutidas, como tipos de dados, valores mÃ­nimos/mÃ¡ximos, valores ausentes, padrÃµes regex e mais. AlÃ©m disso, Ã© possÃ­vel criar validaÃ§Ãµes personalizadas.

4. **Limpeza de Dados**: AlÃ©m da validaÃ§Ã£o, a Pandera tambÃ©m oferece funcionalidades para limpeza de dados, como preenchimento de valores ausentes, remoÃ§Ã£o de valores duplicados e conversÃ£o de tipos de dados.

5. **Compatibilidade com Tipagem EstÃ¡tica**: CompatÃ­vel com tipagem estÃ¡tica, permitindo fÃ¡cil integraÃ§Ã£o com sistemas que fazem uso de tipagem estÃ¡tica, como mypy.

Em resumo, Pandera Ã© uma ferramenta poderosa para garantir a integridade e a qualidade dos dados em dataframes Pandas, ajudando a tornar o processo de anÃ¡lise de dados mais confiÃ¡vel e eficiente.
Link do projeto: [Pandera](https://pypi.org/project/pandera/)

* **Criando o Schema de validaÃ§Ã£o do Pandera.**:


```python
%%writefile src/utils/schema.py
# Schema para validaÃ§Ã£o
import pandera as pa
from pandera.typing import Series

class VendasSchema(pa.SchemaModel):
    Produto: Series[str]
    Categoria: Series[str]
    Quantidade: Series[int] = pa.Field(ge=0)  # ge=0 significa "maior ou igual a 0"
    Venda: Series[int] = pa.Field(ge=0)
    Data: Series[str]

    class Config:
        coerce = True
        strict = True
```

    Writing src/utils/schema.py


#### DocumentaÃ§Ã£o do VendasSchema

O `VendasSchema` Ã© uma classe definida na biblioteca Pandera que define um esquema para validar e limpar dados relacionados a vendas.

##### Atributos:
- `Produto`: Uma sÃ©rie de strings representando os nomes dos produtos.
- `Categoria`: Uma sÃ©rie de strings representando as categorias dos produtos.
- `Quantidade`: Uma sÃ©rie de inteiros representando a quantidade de produtos vendidos. Deve ser maior ou igual a 0.
- `Venda`: Uma sÃ©rie de inteiros representando o valor de venda dos produtos. Deve ser maior ou igual a 0.
- `Data`: Uma sÃ©rie de strings representando as datas das vendas.

##### ConfiguraÃ§Ãµes:
- `coerce`: Define se os tipos de dados devem ser coercÃ­veis (ou seja, convertidos automaticamente) para os tipos definidos no esquema. Neste caso, estÃ¡ definido como True.
- `strict`: Define se a validaÃ§Ã£o deve ser estrita, ou seja, se os dados devem corresponder exatamente ao esquema definido. Neste caso, estÃ¡ definido como True.

* **Incorporando o decorator pandera ao script de etl**:


```python
%%writefile src/etl.py
# Desafio ETL
import glob
import os
from typing import List
#importando os decorators
from utils.timer_decorator import timer
from utils.log_decorator import log_decorator
from utils.schema import VendasSchema
import pandera as pa
import pandas as pd

@pa.check_output(VendasSchema)
def ler_arquivos_json(path_origin: str) -> pd.DataFrame:
    caminho_arquivos = os.path.join(path_origin, "*.json")
    arquivos_json = glob.glob(caminho_arquivos)
    if not arquivos_json:
        raise ValueError("Nenhum arquivo JSON encontrado na pasta especificada.")
    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]
    return pd.concat(dfs, ignore_index=True)


def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    df["Receita"] = df["Quantidade"] * df["Venda"]
    return df


def carregar_dataframe(
    df: pd.DataFrame, path_to_save: str, format_to_save: List[str]
) -> None:
    for formato in format_to_save:
        if formato.lower() == "csv":
            caminho_salvar_csv = path_to_save + ".csv"
            df.to_csv(caminho_salvar_csv, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_csv}'")
        elif formato.lower() == "parquet":
            caminho_salvar_parquet = path_to_save + ".parquet"
            df.to_parquet(caminho_salvar_parquet, index=False)
            print(f"DataFrame salvo em '{caminho_salvar_parquet}'")
        else:
            raise ValueError(
                "Formato especificado nÃ£o suportado. Use 'csv' ou 'parquet'."
            )

@log_decorator
@timer
def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:
    df = ler_arquivos_json(path_origin)
    df = transformar_dataframe(df)
    carregar_dataframe(df, path_to_save, format_to_save)


if __name__ == "__main__":
    path_to_save = "data/process/dados_processados"
    path_origin = "data/"
    format_to_save = ["csv", "parquet"]  # ou 'parquet'

    pipeline(path_origin, path_to_save, format_to_save)

```

    Overwriting src/etl.py


* **ExecuÃ§Ã£o da pipeline com o decorator pandera**:


```python
!python src/pipeline.py
```

    /home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.
      warnings.warn(
    2024-04-10T00:07:19.978725-0300 [31mINFO[0m [32mChamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {}[0m log_decorator.py
    DataFrame salvo em 'data/process/dados_processados.csv'
    DataFrame salvo em 'data/process/dados_processados.parquet'
    2024-04-10T00:07:20.042259-0300 [31mINFO[0m [32mFunction 'pipeline' executed in 0:00:00.063039[0m timer_decorator.py
    2024-04-10T00:07:20.042650-0300 [31mINFO[0m [32m'pipeline' retornou None[0m log_decorator.py


* **Vamos acessar o log**:


```python
# %load log/app.log
2024-04-10T00:07:19.978725-0300 INFO Chamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {} log_decorator.py
2024-04-10T00:07:20.042259-0300 INFO Function 'pipeline' executed in 0:00:00.063039 timer_decorator.py
2024-04-10T00:07:20.042650-0300 INFO 'pipeline' retornou None log_decorator.py

```

* **Veja que o todos os testes com o Pandera passaram.**
* **Agora vamos simular um erro por exemplo, alguÃ©m digitou "Produto" com "Product" e ver se o erro acontece.**


```python
%%writefile data/coleta_dia03.json
[
    {
        "Prodct": "Notebook Gamer",
        "Categoria": "EletrÃ´nicos",
        "Quantidade": 2,
        "Venda": 1500,
        "Data": "2023-01-17"
    },
    {
        "Produto": "Mouse Sem Fio",
        "Categoria": "EletrÃ´nicos",
        "Quantidade": 14,
        "Venda": 30,
        "Data": "2023-01-17"
    },
    {
        "Produto": "Teclado MecÃ¢nico",
        "Categoria": "EletrÃ´nicos",
        "Quantidade": 2,
        "Venda": 100,
        "Data": "2023-01-17"
    }
]

```

    Overwriting data/coleta_dia03.json


* **Agora vamos rodar o script**:


```python
!python src/pipeline.py
```

* **Vamos acessar o arquivo de log:**


```python
# %load log/app.log
2024-04-10T00:07:19.978725-0300 INFO Chamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {} log_decorator.py
2024-04-10T00:07:20.042259-0300 INFO Function 'pipeline' executed in 0:00:00.063039 timer_decorator.py
2024-04-10T00:07:20.042650-0300 INFO 'pipeline' retornou None log_decorator.py
2024-04-10T00:08:02.114924-0300 INFO Chamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {} log_decorator.py
2024-04-10T00:08:02.137134-0300 ERROR 'pipeline' lanÃ§ou uma exceÃ§Ã£o: error in check_output decorator of function 'ler_arquivos_json': column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(name=Categoria, type=DataType(str))>, 'Quantidade': <Schema Column(name=Quantidade, type=DataType(int64))>, 'Venda': <Schema Column(name=Venda, type=DataType(int64))>, 'Data': <Schema Column(name=Data, type=DataType(str))>} log_decorator.py
Traceback (most recent call last):

  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py", line 371, in _try_validate
    return schema.validate(
           â”‚      â”” <classmethod(<function DataFrameModel.validate at 0x7fafe0836680>)>
           â”” VendasSchema
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/pandas/model.py", line 306, in validate
    cls.to_schema().validate(
    â”‚   â”” <classmethod(<function DataFrameModel.to_schema at 0x7fafe08364d0>)>
    â”” VendasSchema
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/pandas/container.py", line 375, in validate
    return self._validate(
           â”‚    â”” <function DataFrameSchema._validate at 0x7fafe07e80d0>
           â”” <Schema DataFrameSchema(columns={'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(na...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/pandas/container.py", line 404, in _validate
    return self.get_backend(check_obj).validate(
           â”‚    â”‚           â””             Produto    Categoria  Quantidade  Venda        Data          Prodct
           â”‚    â”‚             0    Notebook Gamer  EletrÃ´nicos           3 ...
           â”‚    â”” <classmethod(<function BaseSchema.get_backend at 0x7fafe07c5630>)>
           â”” <Schema DataFrameSchema(columns={'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(na...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/backends/pandas/container.py", line 84, in validate
    error_handler.collect_error(
    â”‚             â”” <function ErrorHandler.collect_error at 0x7fafe08115a0>
    â”” <pandera.api.base.error_handler.ErrorHandler object at 0x7fafe08a5240>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/base/error_handler.py", line 54, in collect_error
    raise schema_error from original_exc
          â”‚                 â”” None
          â”” SchemaError("column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/backends/pandas/container.py", line 82, in validate
    check_obj = parser(check_obj, *args)
                â”‚      â”‚           â”” (<Schema DataFrameSchema(columns={'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(n...
                â”‚      â””             Produto    Categoria  Quantidade  Venda        Data          Prodct
                â”‚        0    Notebook Gamer  EletrÃ´nicos           3 ...
                â”” <bound method DataFrameSchemaBackend.strict_filter_columns of <pandera.backends.pandas.container.DataFrameSchemaBackend objec...
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/backends/pandas/container.py", line 492, in strict_filter_columns
    raise SchemaError(
          â”” <class 'pandera.errors.SchemaError'>

pandera.errors.SchemaError: column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(name=Categoria, type=DataType(str))>, 'Quantidade': <Schema Column(name=Quantidade, type=DataType(int64))>, 'Venda': <Schema Column(name=Venda, type=DataType(int64))>, 'Data': <Schema Column(name=Data, type=DataType(str))>}


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/pipeline.py", line 7, in <module>
    pipeline(path_origin, path_to_save, format_to_save)
    â”‚        â”‚            â”‚             â”” ['csv', 'parquet']
    â”‚        â”‚            â”” 'data/process/dados_processados'
    â”‚        â”” 'data/'
    â”” <function pipeline at 0x7fafe089d240>

> File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/log_decorator.py", line 53, in wrapper
    result = func(*args, **kwargs)
             â”‚     â”‚       â”” {}
             â”‚     â”” ('data/', 'data/process/dados_processados', ['csv', 'parquet'])
             â”” <function pipeline at 0x7fafe089d1b0>

  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/timer_decorator.py", line 10, in wrapper
    result = func(*args, **kwargs)
             â”‚     â”‚       â”” {}
             â”‚     â”” ('data/', 'data/process/dados_processados', ['csv', 'parquet'])
             â”” <function pipeline at 0x7fafe089d120>

  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/etl.py", line 47, in pipeline
    df = ler_arquivos_json(path_origin)
         â”‚                 â”” 'data/'
         â”” <FunctionWrapper at 0x7fafe086f0a0 for function at 0x7fafe089cca0>

  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py", line 424, in _wrapper
    return validate(out, fn)
           â”‚        â”‚    â”” <function ler_arquivos_json at 0x7fafe089cca0>
           â”‚        â””             Produto    Categoria  Quantidade  Venda        Data          Prodct
           â”‚          0    Notebook Gamer  EletrÃ´nicos           3 ...
           â”” <function check_output.<locals>.validate at 0x7fb02d8cf9a0>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py", line 378, in validate
    return _try_validate(out)
           â”‚             â””             Produto    Categoria  Quantidade  Venda        Data          Prodct
           â”‚               0    Notebook Gamer  EletrÃ´nicos           3 ...
           â”” <function check_output.<locals>.validate.<locals>._try_validate at 0x7fb02d9a7d90>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py", line 375, in _try_validate
    _handle_schema_error("check_output", fn, schema, obj, e)
    â”‚                                    â”‚   â”‚       â””             Produto    Categoria  Quantidade  Venda        Data          Prodct
    â”‚                                    â”‚   â”‚         0    Notebook Gamer  EletrÃ´nicos           3 ...
    â”‚                                    â”‚   â”” VendasSchema
    â”‚                                    â”” <function ler_arquivos_json at 0x7fafe089cca0>
    â”” <function _handle_schema_error at 0x7fafe089c0d0>
  File "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py", line 100, in _handle_schema_error
    raise _parse_schema_error(
          â”” <function _parse_schema_error at 0x7fafe089c160>

pandera.errors.SchemaError: error in check_output decorator of function 'ler_arquivos_json': column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(name=Categoria, type=DataType(str))>, 'Quantidade': <Schema Column(name=Quantidade, type=DataType(int64))>, 'Venda': <Schema Column(name=Venda, type=DataType(int64))>, 'Data': <Schema Column(name=Data, type=DataType(str))>}

```

* **Veja que o log mostra exatamente a coluna que encontrou o erro de validaÃ§Ã£o e nÃ£o passou adiante.**

* **Com isso conseguimos concluir que ao usar o Loguru e o Pandera como decorators Ã© essencial para garantir a qualidade e monitoramento dos dados em aplicaÃ§Ãµes Python. O Loguru permite um registro eficiente e flexÃ­vel de eventos, facilitando a identificaÃ§Ã£o e resoluÃ§Ã£o de problemas. Enquanto isso, o Pandera oferece uma validaÃ§Ã£o robusta de dados, garantindo a integridade e consistÃªncia dos mesmos. Juntos, esses decorators fornecem uma abordagem abrangente para garantir a qualidade dos dados e facilitar o monitoramento por meio de logs em caso de erros, contribuindo para a confiabilidade e eficiÃªncia das aplicaÃ§Ãµes.**
