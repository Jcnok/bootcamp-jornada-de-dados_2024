{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb7cd84-4631-4d4f-9dc8-95f158034ba7",
   "metadata": {},
   "source": [
    "# Funções em Python - ETL com Pandas, JSON e Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447c312-6fb7-45b9-a842-3c9f46f24fb3",
   "metadata": {},
   "source": [
    "Para realizar uma ETL (Extract, Transform, Load) simples utilizando Python e a biblioteca Pandas, vamos seguir os seguintes passos:\n",
    "\n",
    "Extract: Ler os dados de um arquivo JSON.\n",
    "\n",
    "Transform: Concatenar os dados extraídos em um único DataFrame e aplicar uma transformação. A transformação específica dependerá dos dados, mas vamos assumir uma operação simples como um exemplo.\n",
    "\n",
    "Load: Salvar o DataFrame resultante em um arquivo CSV ou PARQUET."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f12bbe-4c6f-4ab5-8245-48d85331a7ea",
   "metadata": {},
   "source": [
    "## Selecionando a raiz do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fe0773-7b73-49ce-94b2-8e4e8ce2c346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff8fbb-c333-409b-830c-bcfb28598ef1",
   "metadata": {},
   "source": [
    "## Loguru: Simplificando o Registro em Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a64ed3-3c3e-457c-bcae-b6fcae7cd8b6",
   "metadata": {},
   "source": [
    "O Loguru é uma biblioteca de registro (logging) para Python que simplifica bastante o processo de registro de mensagens de registro (logs) em aplicativos Python. Ele oferece uma API fácil de usar e poderosa para configurar e gerenciar logs em seus projetos.\n",
    "\n",
    "### Principais Características\n",
    "\n",
    "1. **API Simples**: O Loguru oferece uma API muito simples e intuitiva para registro de mensagens. Você pode facilmente configurar o registro com apenas algumas linhas de código.\n",
    "\n",
    "2. **Níveis de Log Personalizáveis**: Ele fornece vários níveis de log predefinidos (por exemplo, DEBUG, INFO, WARNING, ERROR, etc.) e também permite a definição de níveis de log personalizados conforme necessário.\n",
    "\n",
    "3. **Formatação Flexível**: Você pode personalizar facilmente o formato das mensagens de log de acordo com suas necessidades. O Loguru oferece suporte a formatação de mensagem flexível e extensível.\n",
    "\n",
    "4. **Suporte a Threads e Processos**: Loguru lida automaticamente com problemas de concorrência em aplicativos que usam várias threads ou processos, garantindo que as mensagens de log sejam registradas corretamente e sem conflitos.\n",
    "\n",
    "5. **Integração com Outras Ferramentas**: Ele se integra facilmente com outras ferramentas e bibliotecas, como Flask, Django, e outras ferramentas populares de registro em Python.\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "O Loguru simplifica o processo de registro de mensagens de log em aplicativos Python, oferecendo uma API fácil de usar, flexibilidade na formatação de mensagens e uma série de recursos úteis para gerenciamento eficaz de logs. É uma escolha popular entre os desenvolvedores Python devido à sua simplicidade e poder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98418781-40c7-4c51-9aa3-43f20ec3b807",
   "metadata": {},
   "source": [
    "### O que é Logging?\n",
    "\n",
    "Logging é o processo de gravar mensagens que documentam os eventos que ocorrem durante a execução de um software. Essas mensagens podem indicar progresso da execução, falhas, erros, ou outras informações úteis. O logging é crucial para desenvolvimento e manutenção de software, pois permite aos desenvolvedores e administradores de sistema entender o que o aplicativo está fazendo, diagnosticar problemas e monitorar o desempenho em produção.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd09bc-3b0a-46e0-942e-36b8cf466fca",
   "metadata": {},
   "source": [
    "### Instalação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d82727f1-e9d7-4fd9-bcd3-db6283b2dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add loguru -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a628938-643c-42ec-b87a-bc9a6f131334",
   "metadata": {},
   "source": [
    "### Como usar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d259785-9536-4b39-8c90-b98429f14927",
   "metadata": {},
   "source": [
    "* **Configuração Básica e Registro de Mensagens Simples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2acaa-69f7-44e8-bef8-3899f99d78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "\n",
    "# Configuração básica\n",
    "logger.add(\"log/app.log\", rotation=\"5 MB\", level=\"WARNING\")\n",
    "\n",
    "# Exemplos de registro de mensagens\n",
    "logger.debug(\"Esta é uma mensagem de depuração\")\n",
    "logger.info(\"Esta é uma mensagem informativa\")\n",
    "logger.warning(\"Esta é uma mensagem de aviso\")\n",
    "logger.error(\"Esta é uma mensagem de erro\")\n",
    "logger.critical(\"Esta é uma mensagem crítica\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddae0bb-aff5-4fb2-9310-8c21ef7b89bf",
   "metadata": {},
   "source": [
    "![img](../img/loguru_basic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72f88d-508f-4bdb-8070-52256df8a246",
   "metadata": {},
   "source": [
    "* **Agora vamos acessar o arquivo app.log e conferir que ele só salvou os logs de level \"WARNING\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db5c37c-495a-47c6-a658-4ab846bef646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load log/app.log\n",
    "2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta é uma mensagem de aviso\n",
    "2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta é uma mensagem de erro\n",
    "2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta é uma mensagem crítica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be457e-6f77-4884-9041-78793f6b9b31",
   "metadata": {},
   "source": [
    "* **Veja que o level \"WARNING\" não salva os logs do tipo 'INFO' e 'DEBUB'.**\n",
    "* **Assim podemos configurar os níveis de logs conforme a necessidade.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d27e08-c9de-4ddf-bf87-8481a317fd2a",
   "metadata": {},
   "source": [
    "### Personalização dos logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55867e-22db-441b-aab9-70ae5f3f4096",
   "metadata": {},
   "source": [
    "* **Personalizando o formato das mensagens:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4852f-1bb3-4b27-b3ad-c016d0ad65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "\n",
    "# Configuração com formato personalizado\n",
    "logger.add(\"log/app.log\", format=\"{time} - {level} - {message}\", level=\"INFO\")\n",
    "\n",
    "# Exemplo de registro de mensagem com contexto\n",
    "logger.info(\"Usuário {user} fez login\", user=\"Julio Okuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f54c7-69b7-46c1-bbb0-2e61513971d7",
   "metadata": {},
   "source": [
    "![img](../img/personalize_loguru.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93fbda-cb59-4d69-8acb-d8d399f4b21a",
   "metadata": {},
   "source": [
    "* **Acessando o conteúdo do arquivo app.log:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d916ef9-0bf1-4592-8523-30e59d1b7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load log/app.log\n",
    "2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta é uma mensagem de aviso\n",
    "2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta é uma mensagem de erro\n",
    "2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta é uma mensagem crítica\n",
    "2024-04-09T01:20:43.014364-0300 - INFO - Usuário Julio Okuda fez login\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4dfdf-b1bc-4ad9-9e7b-b6595d821dfc",
   "metadata": {},
   "source": [
    "* **Tratamento de exceções**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4d082-877d-4ccf-a44a-dcc69dd03838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "\n",
    "try:\n",
    "    # Algum código que pode gerar uma exceção\n",
    "    resultado = 1 / 0\n",
    "except Exception as e:\n",
    "    # Registro da exceção com o método exception()\n",
    "    logger.exception(\"Ocorreu um erro inesperado: {exception}\", exception=str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3929615-5054-4eb8-9b96-0c5f03982e18",
   "metadata": {},
   "source": [
    "![img](../img/exception.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38978572-b9bc-4c42-890e-53b88c01eb31",
   "metadata": {},
   "source": [
    "Usando logger.exception(), Loguru automaticamente captura e loga o traceback da exceção, o que é extremamente útil para diagnóstico de erros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038cf6c-345a-439e-a2a8-704cda86554e",
   "metadata": {},
   "source": [
    "* **Vamos criar um decorador utilizando o Loguru para adicionar automaticamente logs a qualquer função Python. Isso nos permite registrar automaticamente quando uma função é chamada e quando ela termina, junto com qualquer informação relevante, como argumentos da função e o resultado retornado (ou exceção lançada).**\n",
    "\n",
    "* **Agora, vamos ao código do decorador:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf7900ee-7aa5-4dbd-ad5f-e19d72f73df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/utils/log_decorator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/log_decorator.py\n",
    "# decorator para registro de logs\n",
    "from loguru import logger\n",
    "\n",
    "def log_decorator(func):\n",
    "    \"\"\"\n",
    "    Decorador para registro de chamadas de função com o Loguru.\n",
    "\n",
    "    Args:\n",
    "        func (callable): Função a ser decorada.\n",
    "\n",
    "    Returns:\n",
    "        callable: Função decorada.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        \"\"\"\n",
    "        Função interna que envolve a função original e realiza o registro.\n",
    "\n",
    "        Args:\n",
    "            *args: Argumentos posicionais passados para a função.\n",
    "            **kwargs: Argumentos de palavras-chave passados para a função.\n",
    "\n",
    "        Returns:\n",
    "            Qualquer: Resultado da função original.\n",
    "\n",
    "        Raises:\n",
    "            Exception: Se a função original lançar uma exceção.\n",
    "        \"\"\"\n",
    "        # Registra a chamada da função com os argumentos e palavras-chave\n",
    "        logger.info(f\"Chamando '{func.__name__}' com {args} e {kwargs}\")\n",
    "        \n",
    "        try:\n",
    "            # Chama a função original e captura o resultado\n",
    "            result = func(*args, **kwargs)\n",
    "            # Registra o retorno da função\n",
    "            logger.info(f\"'{func.__name__}' retornou {result}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            # Registra a exceção se a função original lançar uma exceção\n",
    "            logger.exception(f\"'{func.__name__}' lançou uma exceção: {e}\")\n",
    "            # Propaga a exceção para cima na cadeia de chamadas\n",
    "            raise\n",
    "    \n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4bd16-77ca-410d-84f8-121a105217a8",
   "metadata": {},
   "source": [
    "### Uso e Execução do Decorador de Registro com Loguru\n",
    "\n",
    "O decorador `log_decorator` é uma ferramenta útil para registrar chamadas de função em aplicativos Python usando a biblioteca Loguru. Este decorador pode ser aplicado a qualquer função para automatizar o registro de suas chamadas e resultados.\n",
    "\n",
    "#### Como Usar o Decorador\n",
    "\n",
    "Para usar o decorador `log_decorator`, siga estas etapas:\n",
    "\n",
    "1. **Importe o Decorador**: Importe o decorador `log_decorator` de onde ele estiver definido no seu código.\n",
    "\n",
    "2. **Aplique o Decorador**: Aplique o decorador `log_decorator` à função que deseja registrar. Por exemplo:\n",
    "\n",
    "    ```python\n",
    "    @log_decorator\n",
    "    def minha_funcao(parametro):\n",
    "        # Corpo da função\n",
    "        pass\n",
    "    ```\n",
    "\n",
    "    Isso irá decorar a função `minha_funcao` com o decorador de registro, permitindo que todas as suas chamadas sejam registradas automaticamente.\n",
    "\n",
    "#### Execução do Decorador\n",
    "\n",
    "Quando uma função decorada com `log_decorator` é chamada, o decorador entra em ação:\n",
    "\n",
    "1. **Registro de Chamada**: O decorador registra a chamada da função, incluindo os argumentos passados.\n",
    "\n",
    "2. **Execução da Função Original**: O decorador chama a função original com os argumentos fornecidos.\n",
    "\n",
    "3. **Registro de Resultado**: Se a função for executada com sucesso, o decorador registra o resultado retornado.\n",
    "\n",
    "4. **Gestão de Exceções**: Se a função lançar uma exceção durante a execução, o decorador registra a exceção e a propaga para cima na cadeia de chamadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fed6ce-1be5-4580-98ee-e2cc3885a152",
   "metadata": {},
   "source": [
    "### Como Utilizar o Decorador\n",
    "\n",
    "Agora, veja como aplicar o `log_decorator` a uma função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "353f5284-1665-43ff-ac9d-03c74615cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#primeir devemos imporar o decorador \n",
    "from src.utils.log_decorator import log_decorator\n",
    "@log_decorator\n",
    "def soma(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6141d4d-168e-45a4-b60b-5b2332adbba3",
   "metadata": {},
   "source": [
    "* **Veja um exemplo de uma função bem simples usando o decorador que acabamos de criar**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a8cd4-4828-4a85-9072-9824f7958eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução da função soma \n",
    "soma(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2eb76-37f8-461f-8a71-473781c85dab",
   "metadata": {},
   "source": [
    "![decorator_soma](../img/decorator_soma.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b3ed3-34c1-403e-b9e8-27a1c8d489e4",
   "metadata": {},
   "source": [
    "* **O decorator encapsulou a função e já imprimiu os logs do tipo INFO.**\n",
    "* **Será que o log foi registrado no app.log?**\n",
    "  * Como havia configurado o level para \"INFO\" esse log, deve estar registrado no arquivo vamos conferir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50f4c134-9162-46b0-848d-be98ac4f36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load log/app.log\n",
    "2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta é uma mensagem de aviso\n",
    "2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta é uma mensagem de erro\n",
    "2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta é uma mensagem crítica\n",
    "2024-04-09T01:20:43.014364-0300 - INFO - Usuário Julio Okuda fez login\n",
    "2024-04-09T01:54:01.939913-0300 - INFO - Chamando 'soma' com (5, 3) e {}\n",
    "2024-04-09T01:54:01.946493-0300 - INFO - 'soma' retornou 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78953ff-5f91-4f93-9309-a3c6c2b2f109",
   "metadata": {},
   "source": [
    "* **Realizando um teste de falha**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7bc1a-fc26-49aa-adf6-59049db07319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizando uma soma que irá falhar \n",
    "soma(3, \"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411cda5d-cfd6-4a77-a00e-cff9a4529ffc",
   "metadata": {},
   "source": [
    "* **Vamos acessar o arquivo de log**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb18821-8c7f-4430-b868-0d8a2ff9a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load log/app.log\n",
    "2024-04-09 01:16:32.796 | WARNING  | __main__:<module>:9 - Esta é uma mensagem de aviso\n",
    "2024-04-09 01:16:32.801 | ERROR    | __main__:<module>:10 - Esta é uma mensagem de erro\n",
    "2024-04-09 01:16:32.805 | CRITICAL | __main__:<module>:11 - Esta é uma mensagem crítica\n",
    "2024-04-09T01:20:43.014364-0300 - INFO - Usuário Julio Okuda fez login\n",
    "2024-04-09T01:54:01.939913-0300 - INFO - Chamando 'soma' com (5, 3) e {}\n",
    "2024-04-09T01:54:01.946493-0300 - INFO - 'soma' retornou 8\n",
    "2024-04-09T02:04:21.395570-0300 - INFO - Chamando 'soma' com (3, '3') e {}\n",
    "2024-04-09 02:04:21.402 | ERROR    | src.utils.log_decorator:wrapper:39 - 'soma' lançou uma exceção: unsupported operand type(s) for +: 'int' and 'str'\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
    "    return _run_code(code, main_globals, None,\n",
    "           │         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
    "           │         └ <code object <module> at 0x7f795a3533c0, file \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...\n",
    "           └ <function _run_code at 0x7f795a35fac0>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 86, in _run_code\n",
    "    exec(code, run_globals)\n",
    "         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
    "         └ <code object <module> at 0x7f795a3533c0, file \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
    "    app.launch_new_instance()\n",
    "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
    "    └ <module 'ipykernel.kernelapp' from '/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/i...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
    "    app.start()\n",
    "    │   └ <function IPKernelApp.start at 0x7f79576943a0>\n",
    "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
    "    self.io_loop.start()\n",
    "    │    │       └ <function BaseAsyncIOLoop.start at 0x7f7957694ee0>\n",
    "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>\n",
    "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
    "    self.asyncio_loop.run_forever()\n",
    "    │    │            └ <function BaseEventLoop.run_forever at 0x7f7959232f80>\n",
    "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
    "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
    "    self._run_once()\n",
    "    │    └ <function BaseEventLoop._run_once at 0x7f7959234af0>\n",
    "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
    "    handle._run()\n",
    "    │      └ <function Handle._run at 0x7f795994c160>\n",
    "    └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
    "    self._context.run(self._callback, *self._args)\n",
    "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
    "    │    │            │    │           └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
    "    │    │            └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "    │    └ <member '_context' of 'Handle' objects>\n",
    "    └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
    "    await self.process_one()\n",
    "          │    └ <function Kernel.process_one at 0x7f7957ab2320>\n",
    "          └ <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
    "    await dispatch(*args)\n",
    "          │         └ ([<zmq.sugar.frame.Frame object at 0x7f79444b6fb0>, <zmq.sugar.frame.Frame object at 0x7f7944451430>, <zmq.sugar.frame.Frame ...\n",
    "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
    "    await result\n",
    "          └ <coroutine object IPythonKernel.execute_request at 0x7f7944407220>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
    "    await super().execute_request(stream, ident, parent)\n",
    "                                  │       │      └ {'header': {'date': datetime.datetime(2024, 4, 9, 5, 4, 21, 389000, tzinfo=tzutc()), 'msg_id': '08c451f7-fbb9-4ff8-979a-5a9b4...\n",
    "                                  │       └ [b'4455ded5-0c77-428d-affa-44648e506000']\n",
    "                                  └ <zmq.eventloop.zmqstream.ZMQStream object at 0x7f795768ff70>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
    "    reply_content = await reply_content\n",
    "                          └ <coroutine object IPythonKernel.do_execute at 0x7f7944405fc0>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
    "    res = shell.run_cell(\n",
    "          │     └ <function ZMQInteractiveShell.run_cell at 0x7f7957675a20>\n",
    "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
    "    return super().run_cell(*args, **kwargs)\n",
    "                             │       └ {'store_history': True, 'silent': False, 'cell_id': '07b7bc1a-fc26-49aa-adf6-59049db07319'}\n",
    "                             └ ('# realizando uma soma que irá falhar \\nsoma(3, \"3\")',)\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
    "    result = self._run_cell(\n",
    "             │    └ <function InteractiveShell._run_cell at 0x7f795861e560>\n",
    "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
    "    result = runner(coro)\n",
    "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>\n",
    "             └ <function _pseudo_sync_runner at 0x7f795860dea0>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
    "    coro.send(None)\n",
    "    │    └ <method 'send' of 'coroutine' objects>\n",
    "    └ <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
    "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
    "                       │    │             │        │     └ '/tmp/ipykernel_15051/3086203311.py'\n",
    "                       │    │             │        └ [<ast.Expr object at 0x7f7944244dc0>]\n",
    "                       │    │             └ <ast.Module object at 0x7f7944245db0>\n",
    "                       │    └ <function InteractiveShell.run_ast_nodes at 0x7f795861e830>\n",
    "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
    "    if await self.run_code(code, result, async_=asy):\n",
    "             │    │        │     │              └ False\n",
    "             │    │        │     └ <ExecutionResult object at 7f79442447f0, execution_count=21 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
    "             │    │        └ <code object <module> at 0x7f79442ccc90, file \"/tmp/ipykernel_15051/3086203311.py\", line 1>\n",
    "             │    └ <function InteractiveShell.run_code at 0x7f795861e8c0>\n",
    "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
    "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "         │         │    └ <property object at 0x7f7958603b00>\n",
    "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "         └ <code object <module> at 0x7f79442ccc90, file \"/tmp/ipykernel_15051/3086203311.py\", line 1>\n",
    "\n",
    "  File \"/tmp/ipykernel_15051/3086203311.py\", line 2, in <module>\n",
    "    soma(3, \"3\")\n",
    "    └ <function log_decorator.<locals>.wrapper at 0x7f7944922830>\n",
    "\n",
    "> File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/log_decorator.py\", line 33, in wrapper\n",
    "    result = func(*args, **kwargs)\n",
    "             │     │       └ {}\n",
    "             │     └ (3, '3')\n",
    "             └ <function soma at 0x7f7944921750>\n",
    "\n",
    "  File \"/tmp/ipykernel_15051/1321141747.py\", line 5, in soma\n",
    "    return a + b\n",
    "           │   └ '3'\n",
    "           └ 3\n",
    "\n",
    "TypeError: unsupported operand type(s) for +: 'int' and 'str'\n",
    "2024-04-09T02:04:21.402181-0300 - ERROR - 'soma' lançou uma exceção: unsupported operand type(s) for +: 'int' and 'str'\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
    "    return _run_code(code, main_globals, None,\n",
    "           │         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
    "           │         └ <code object <module> at 0x7f795a3533c0, file \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...\n",
    "           └ <function _run_code at 0x7f795a35fac0>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 86, in _run_code\n",
    "    exec(code, run_globals)\n",
    "         │     └ {'__name__': '__main__', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nThis is separate from the ipykernel pack...\n",
    "         └ <code object <module> at 0x7f795a3533c0, file \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
    "    app.launch_new_instance()\n",
    "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
    "    └ <module 'ipykernel.kernelapp' from '/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/i...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
    "    app.start()\n",
    "    │   └ <function IPKernelApp.start at 0x7f79576943a0>\n",
    "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
    "    self.io_loop.start()\n",
    "    │    │       └ <function BaseAsyncIOLoop.start at 0x7f7957694ee0>\n",
    "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>\n",
    "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7f795a2f9030>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
    "    self.asyncio_loop.run_forever()\n",
    "    │    │            └ <function BaseEventLoop.run_forever at 0x7f7959232f80>\n",
    "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
    "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f79574f4220>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
    "    self._run_once()\n",
    "    │    └ <function BaseEventLoop._run_once at 0x7f7959234af0>\n",
    "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
    "    handle._run()\n",
    "    │      └ <function Handle._run at 0x7f795994c160>\n",
    "    └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "  File \"/home/jcnok/.pyenv/versions/3.10.13/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
    "    self._context.run(self._callback, *self._args)\n",
    "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
    "    │    │            │    │           └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
    "    │    │            └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "    │    └ <member '_context' of 'Handle' objects>\n",
    "    └ <Handle Task.task_wakeup(<Future finis...950>, ...],))>)>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
    "    await self.process_one()\n",
    "          │    └ <function Kernel.process_one at 0x7f7957ab2320>\n",
    "          └ <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
    "    await dispatch(*args)\n",
    "          │         └ ([<zmq.sugar.frame.Frame object at 0x7f79444b6fb0>, <zmq.sugar.frame.Frame object at 0x7f7944451430>, <zmq.sugar.frame.Frame ...\n",
    "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7f79574f4820>>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
    "    await result\n",
    "          └ <coroutine object IPythonKernel.execute_request at 0x7f7944407220>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
    "    await super().execute_request(stream, ident, parent)\n",
    "                                  │       │      └ {'header': {'date': datetime.datetime(2024, 4, 9, 5, 4, 21, 389000, tzinfo=tzutc()), 'msg_id': '08c451f7-fbb9-4ff8-979a-5a9b4...\n",
    "                                  │       └ [b'4455ded5-0c77-428d-affa-44648e506000']\n",
    "                                  └ <zmq.eventloop.zmqstream.ZMQStream object at 0x7f795768ff70>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
    "    reply_content = await reply_content\n",
    "                          └ <coroutine object IPythonKernel.do_execute at 0x7f7944405fc0>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
    "    res = shell.run_cell(\n",
    "          │     └ <function ZMQInteractiveShell.run_cell at 0x7f7957675a20>\n",
    "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
    "    return super().run_cell(*args, **kwargs)\n",
    "                             │       └ {'store_history': True, 'silent': False, 'cell_id': '07b7bc1a-fc26-49aa-adf6-59049db07319'}\n",
    "                             └ ('# realizando uma soma que irá falhar \\nsoma(3, \"3\")',)\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
    "    result = self._run_cell(\n",
    "             │    └ <function InteractiveShell._run_cell at 0x7f795861e560>\n",
    "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
    "    result = runner(coro)\n",
    "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>\n",
    "             └ <function _pseudo_sync_runner at 0x7f795860dea0>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
    "    coro.send(None)\n",
    "    │    └ <method 'send' of 'coroutine' objects>\n",
    "    └ <coroutine object InteractiveShell.run_cell_async at 0x7f7944407840>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
    "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
    "                       │    │             │        │     └ '/tmp/ipykernel_15051/3086203311.py'\n",
    "                       │    │             │        └ [<ast.Expr object at 0x7f7944244dc0>]\n",
    "                       │    │             └ <ast.Module object at 0x7f7944245db0>\n",
    "                       │    └ <function InteractiveShell.run_ast_nodes at 0x7f795861e830>\n",
    "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
    "    if await self.run_code(code, result, async_=asy):\n",
    "             │    │        │     │              └ False\n",
    "             │    │        │     └ <ExecutionResult object at 7f79442447f0, execution_count=21 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
    "             │    │        └ <code object <module> at 0x7f79442ccc90, file \"/tmp/ipykernel_15051/3086203311.py\", line 1>\n",
    "             │    └ <function InteractiveShell.run_code at 0x7f795861e8c0>\n",
    "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
    "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
    "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
    "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "         │         │    └ <property object at 0x7f7958603b00>\n",
    "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f79574f4d00>\n",
    "         └ <code object <module> at 0x7f79442ccc90, file \"/tmp/ipykernel_15051/3086203311.py\", line 1>\n",
    "\n",
    "  File \"/tmp/ipykernel_15051/3086203311.py\", line 2, in <module>\n",
    "    soma(3, \"3\")\n",
    "    └ <function log_decorator.<locals>.wrapper at 0x7f7944922830>\n",
    "\n",
    "> File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/log_decorator.py\", line 33, in wrapper\n",
    "    result = func(*args, **kwargs)\n",
    "             │     │       └ {}\n",
    "             │     └ (3, '3')\n",
    "             └ <function soma at 0x7f7944921750>\n",
    "\n",
    "  File \"/tmp/ipykernel_15051/1321141747.py\", line 5, in soma\n",
    "    return a + b\n",
    "           │   └ '3'\n",
    "           └ 3\n",
    "\n",
    "TypeError: unsupported operand type(s) for +: 'int' and 'str'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e1d4a-d23f-45d9-9a65-de7cf5022cfb",
   "metadata": {},
   "source": [
    "* **Veja que ele salvou o erro com todos os detalhes, por isso determinar o nível de log de acordo com a necessidade é importante, pois não seria interessante salvar todo tipo de log, só iria poluir o registro dificultando a resolução do problema.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c1f8b-ad9b-4b31-8093-b9b96c9c9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste em caso de falha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0014e6-7baa-496b-ad41-aadc2eaa0433",
   "metadata": {},
   "source": [
    "Ao decorar as funções `soma` e `falha` com `@log_decorator`, automaticamente logamos a entrada e saída (ou exceção) dessas funções sem alterar o corpo delas. Isso é especialmente útil para debugar, monitorar a performance de aplicações ou simplesmente manter um registro de quais funções estão sendo chamadas e com quais argumentos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb9474-01a9-49f1-b950-fbadafa35753",
   "metadata": {},
   "source": [
    "#### Benefícios do Uso de Decoradores com Loguru\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b117d9-9cfd-4915-bd3e-def28b5b373f",
   "metadata": {},
   "source": [
    "O uso de decoradores em conjunto com o Loguru fornece uma abordagem elegante e poderosa para adicionar logs a aplicações Python. Sem a necessidade de modificar o corpo da função, podemos facilmente adicionar funcionalidades de logging, o que torna o código mais limpo, mantém a separação de preocupações e facilita a manutenção e o debugging.\n",
    "\n",
    "Além disso, ao centralizar a lógica de logging no decorador, promovemos a reutilização de código e garantimos uma forma consistente de logar informações através de diferentes partes de uma aplicação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70aaff-0bc6-48aa-b166-a2566fb35f37",
   "metadata": {},
   "source": [
    "### Conclusão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710bab1-303c-448a-8804-5e4ec9a889ba",
   "metadata": {},
   "source": [
    "O Loguru oferece uma abordagem moderna e conveniente para logging em Python, simplificando muitos aspectos que requerem configuração manual detalhada com o módulo de logging padrão do Python. Seja para desenvolvimento, depuração ou produção, adicionar logging ao seu aplicativo com Loguru pode melhorar significativamente a visibilidade e a capacidade de diagnóstico do seu código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197c6e1-4a42-4ff2-9362-074caf520144",
   "metadata": {},
   "source": [
    "# Desafio: \n",
    "* **Aplicar decorador de Log, Timer e Qualidade em nossa ETL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750b76d-1056-4dcf-95ea-d7db4a191850",
   "metadata": {},
   "source": [
    "![img](../img/pic_05.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "370f825c-f46a-4340-877f-f7bcae0dc9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/etl.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/etl.py\n",
    "# Desafio ETL\n",
    "import os\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def ler_arquivos_json(path_origin: str) -> pd.DataFrame:\n",
    "    caminho_arquivos = os.path.join(path_origin, '*.json')\n",
    "    arquivos_json = glob.glob(caminho_arquivos)\n",
    "    if not arquivos_json:\n",
    "        raise ValueError(\"Nenhum arquivo JSON encontrado na pasta especificada.\")\n",
    "    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Receita'] = df['Quantidade'] * df['Venda']\n",
    "    return df\n",
    "\n",
    "def carregar_dataframe(df: pd.DataFrame, path_to_save: str, format_to_save: List[str]) -> None:\n",
    "    for formato in format_to_save:\n",
    "        if formato.lower() == 'csv':\n",
    "            caminho_salvar_csv = path_to_save + '.csv'\n",
    "            df.to_csv(caminho_salvar_csv, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_csv}'\")\n",
    "        elif formato.lower() == 'parquet':\n",
    "            caminho_salvar_parquet = path_to_save + '.parquet'\n",
    "            df.to_parquet(caminho_salvar_parquet, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_parquet}'\")\n",
    "        else:\n",
    "            raise ValueError(\"Formato especificado não suportado. Use 'csv' ou 'parquet'.\")\n",
    "\n",
    "def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:\n",
    "    df = ler_arquivos_json(path_origin)\n",
    "    df = transformar_dataframe(df)\n",
    "    carregar_dataframe(df, path_to_save, format_to_save)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_to_save = 'data/process/dados_processados'\n",
    "    path_origin = 'data/'\n",
    "    format_to_save = ['csv','parquet']  # ou 'parquet'\n",
    "    \n",
    "    pipeline(path_origin, path_to_save, format_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fab1d0b-3819-49a0-976d-bf120b440711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame salvo em 'data/process/dados_processados.csv'\n",
      "DataFrame salvo em 'data/process/dados_processados.parquet'\n"
     ]
    }
   ],
   "source": [
    "!python src/etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d478f0b-4e91-47a9-818a-f9b61b7b4fcd",
   "metadata": {},
   "source": [
    "## Resolução do desafio:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97287f6-a3aa-48e2-bc85-6acb8a4d271d",
   "metadata": {},
   "source": [
    "* **Decorators:**\n",
    "* [x] Decorator para computar o tempo de execução;\n",
    "* [x] Decorator para Qualidade de dados usando o pandera ou pydantic\n",
    "* [x] Decorator para logs com loguru."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5bae14-a099-4adc-a0a5-6467585eb4d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Decorator para computar o tempo.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d4a212-8315-41da-b803-ec1257f4c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/timer_decorator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/timer_decorator.py\n",
    "# Decorator para computar o tempo de execução:\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "from functools import wraps\n",
    "\n",
    "def timer(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = datetime.now()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = datetime.now()\n",
    "        elapsed_time = end_time - start_time\n",
    "        logger.info(f\"Function '{func.__name__}' executed in {elapsed_time}\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefce8d1-c6fe-4b73-b638-60f23245d202",
   "metadata": {},
   "source": [
    "* **Incorporando o decorator timer ao script de etl**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e6e693-579f-4b1c-89a0-b8091baff0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/etl.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/etl.py\n",
    "# Desafio ETL\n",
    "import glob\n",
    "import os\n",
    "from typing import List\n",
    "#importando os decorators\n",
    "from utils.timer_decorator import timer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def ler_arquivos_json(path_origin: str) -> pd.DataFrame:\n",
    "    caminho_arquivos = os.path.join(path_origin, \"*.json\")\n",
    "    arquivos_json = glob.glob(caminho_arquivos)\n",
    "    if not arquivos_json:\n",
    "        raise ValueError(\"Nenhum arquivo JSON encontrado na pasta especificada.\")\n",
    "    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Receita\"] = df[\"Quantidade\"] * df[\"Venda\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def carregar_dataframe(\n",
    "    df: pd.DataFrame, path_to_save: str, format_to_save: List[str]\n",
    ") -> None:\n",
    "    for formato in format_to_save:\n",
    "        if formato.lower() == \"csv\":\n",
    "            caminho_salvar_csv = path_to_save + \".csv\"\n",
    "            df.to_csv(caminho_salvar_csv, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_csv}'\")\n",
    "        elif formato.lower() == \"parquet\":\n",
    "            caminho_salvar_parquet = path_to_save + \".parquet\"\n",
    "            df.to_parquet(caminho_salvar_parquet, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_parquet}'\")\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Formato especificado não suportado. Use 'csv' ou 'parquet'.\"\n",
    "            )\n",
    "\n",
    "@timer\n",
    "def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:\n",
    "    df = ler_arquivos_json(path_origin)\n",
    "    df = transformar_dataframe(df)\n",
    "    carregar_dataframe(df, path_to_save, format_to_save)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_to_save = \"data/process/dados_processados\"\n",
    "    path_origin = \"data/\"\n",
    "    format_to_save = [\"csv\", \"parquet\"]  # ou 'parquet'\n",
    "\n",
    "    pipeline(path_origin, path_to_save, format_to_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b88ef0-a8db-4ca0-8fb9-2222bb41ceeb",
   "metadata": {},
   "source": [
    "* **Execução da pipeline com o decorator de timer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f24d409a-7ec0-46b3-8aac-bcada0ab6e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame salvo em 'data/process/dados_processados.csv'\n",
      "DataFrame salvo em 'data/process/dados_processados.parquet'\n",
      "\u001b[32m2024-04-09 23:10:35.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.timer_decorator\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mFunction 'pipeline' executed in 0:00:00.028769\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python src/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8bc140-eb01-4e81-b00c-4760d555a80f",
   "metadata": {},
   "source": [
    "### Decorator para computar o log com loguru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f72c8de-276f-4a92-b5c1-1b8459ddb1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils/log_decorator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/log_decorator.py\n",
    "# decorator para registro de logs\n",
    "from loguru import logger\n",
    "from sys import stderr\n",
    "from functools import wraps\n",
    "\n",
    "# Removendo os handlers existentes para evitar duplicação\n",
    "logger.remove()\n",
    "\n",
    "# Configuração do logger para stderr\n",
    "logger.add(\n",
    "                sink=stderr,\n",
    "                format=\"{time} <r>{level}</r> <g>{message}</g> {file}\",\n",
    "                level=\"INFO\"\n",
    "            )\n",
    "\n",
    "# Configuração do logger para arquivo de log\n",
    "logger.add(\n",
    "                \"log/app.log\",\n",
    "                format=\"{time} {level} {message} {file}\",\n",
    "                level=\"INFO\"\n",
    "            )\n",
    "\n",
    "def log_decorator(func):\n",
    "    \"\"\"\n",
    "    Decorador para registro de chamadas de função com o Loguru.\n",
    "\n",
    "    Args:\n",
    "        func (callable): Função a ser decorada.\n",
    "\n",
    "    Returns:\n",
    "        callable: Função decorada.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        \"\"\"\n",
    "        Função interna que envolve a função original e realiza o registro.\n",
    "\n",
    "        Args:\n",
    "            *args: Argumentos posicionais passados para a função.\n",
    "            **kwargs: Argumentos de palavras-chave passados para a função.\n",
    "\n",
    "        Returns:\n",
    "            Qualquer: Resultado da função original.\n",
    "\n",
    "        Raises:\n",
    "            Exception: Se a função original lançar uma exceção.\n",
    "        \"\"\"\n",
    "        # Registra a chamada da função com os argumentos e palavras-chave\n",
    "        logger.info(f\"Chamando '{func.__name__}' com {args} e {kwargs}\")\n",
    "\n",
    "        try:\n",
    "            # Chama a função original e captura o resultado\n",
    "            result = func(*args, **kwargs)\n",
    "            # Registra o retorno da função\n",
    "            logger.info(f\"'{func.__name__}' retornou {result}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            # Registra a exceção se a função original lançar uma exceção\n",
    "            logger.exception(f\"'{func.__name__}' lançou uma exceção: {e}\")\n",
    "            # Propaga a exceção para cima na cadeia de chamadas\n",
    "            raise\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc50b4-8d24-4699-9e3b-9fd00f36edec",
   "metadata": {},
   "source": [
    "* **Incorporando o decorator timer ao script de etl**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6166e02-4242-4501-958a-2307aaf8d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/etl.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/etl.py\n",
    "# Desafio ETL\n",
    "import glob\n",
    "import os\n",
    "from typing import List\n",
    "#importando os decorators\n",
    "from utils.timer_decorator import timer\n",
    "from utils.log_decorator import log_decorator\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def ler_arquivos_json(path_origin: str) -> pd.DataFrame:\n",
    "    caminho_arquivos = os.path.join(path_origin, \"*.json\")\n",
    "    arquivos_json = glob.glob(caminho_arquivos)\n",
    "    if not arquivos_json:\n",
    "        raise ValueError(\"Nenhum arquivo JSON encontrado na pasta especificada.\")\n",
    "    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Receita\"] = df[\"Quantidade\"] * df[\"Venda\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def carregar_dataframe(\n",
    "    df: pd.DataFrame, path_to_save: str, format_to_save: List[str]\n",
    ") -> None:\n",
    "    for formato in format_to_save:\n",
    "        if formato.lower() == \"csv\":\n",
    "            caminho_salvar_csv = path_to_save + \".csv\"\n",
    "            df.to_csv(caminho_salvar_csv, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_csv}'\")\n",
    "        elif formato.lower() == \"parquet\":\n",
    "            caminho_salvar_parquet = path_to_save + \".parquet\"\n",
    "            df.to_parquet(caminho_salvar_parquet, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_parquet}'\")\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Formato especificado não suportado. Use 'csv' ou 'parquet'.\"\n",
    "            )\n",
    "@log_decorator\n",
    "@timer\n",
    "def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:\n",
    "    df = ler_arquivos_json(path_origin)\n",
    "    df = transformar_dataframe(df)\n",
    "    carregar_dataframe(df, path_to_save, format_to_save)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_to_save = \"data/process/dados_processados\"\n",
    "    path_origin = \"data/\"\n",
    "    format_to_save = [\"csv\", \"parquet\"]  # ou 'parquet'\n",
    "\n",
    "    pipeline(path_origin, path_to_save, format_to_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e9cda-5191-4614-8c9a-c6e53d4f0b9b",
   "metadata": {},
   "source": [
    "* **Execução da pipeline com o decorator**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59748f43-32bf-4455-b518-37e3315785ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-09T23:21:24.577546-0300 \u001b[31mINFO\u001b[0m \u001b[32mChamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {}\u001b[0m log_decorator.py\n",
      "DataFrame salvo em 'data/process/dados_processados.csv'\n",
      "DataFrame salvo em 'data/process/dados_processados.parquet'\n",
      "2024-04-09T23:21:24.608103-0300 \u001b[31mINFO\u001b[0m \u001b[32mFunction 'pipeline' executed in 0:00:00.030056\u001b[0m timer_decorator.py\n",
      "2024-04-09T23:21:24.608452-0300 \u001b[31mINFO\u001b[0m \u001b[32m'pipeline' retornou None\u001b[0m log_decorator.py\n"
     ]
    }
   ],
   "source": [
    "!python src/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa580c-c55c-41e8-8653-7b521f43a276",
   "metadata": {},
   "source": [
    "* **Tanto o decorator de timer quanto o de log estão funcionando**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98863b58-4073-49a5-bdd0-891a080a9c16",
   "metadata": {},
   "source": [
    "### Decorator para computar o log com pandera:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf5d92-1f9a-40fc-baa1-03db9cc35f5d",
   "metadata": {},
   "source": [
    "* **Instação da lib pandera:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f44f6f8-4fc3-4748-842e-800422b3efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add pandera -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032cd30a-e0dd-4b1c-8bc8-ed12612909ed",
   "metadata": {},
   "source": [
    "#### Pandera: Validando e Limpeza de Dados em Dataframes\n",
    "\n",
    "Pandera é uma biblioteca Python usada para validação e limpeza de dados em dataframes, inspirada na biblioteca Pydantic e no esquema JSON Schema. Ele oferece uma maneira simples e declarativa de definir esquemas para validar dados tabulares, como dataframes Pandas.\n",
    "\n",
    "##### Principais Características:\n",
    "\n",
    "1. **Declarativo e Expressivo**: Pandera permite que você defina esquemas de validação de dados de forma declarativa e expressiva, facilitando a compreensão e manutenção das regras de validação.\n",
    "\n",
    "2. **Integração com Pandas**: Construída em cima do Pandas, a Pandera é totalmente integrada com a estrutura de dados de dataframe do Pandas, facilitando a aplicação da validação de dados aos seus dataframes existentes.\n",
    "\n",
    "3. **Validação Extensível**: Oferece uma ampla gama de validações embutidas, como tipos de dados, valores mínimos/máximos, valores ausentes, padrões regex e mais. Além disso, é possível criar validações personalizadas.\n",
    "\n",
    "4. **Limpeza de Dados**: Além da validação, a Pandera também oferece funcionalidades para limpeza de dados, como preenchimento de valores ausentes, remoção de valores duplicados e conversão de tipos de dados.\n",
    "\n",
    "5. **Compatibilidade com Tipagem Estática**: Compatível com tipagem estática, permitindo fácil integração com sistemas que fazem uso de tipagem estática, como mypy.\n",
    "\n",
    "Em resumo, Pandera é uma ferramenta poderosa para garantir a integridade e a qualidade dos dados em dataframes Pandas, ajudando a tornar o processo de análise de dados mais confiável e eficiente.\n",
    "Link do projeto: [Pandera](https://pypi.org/project/pandera/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30e4de-7e89-4147-98ab-80bea62a868e",
   "metadata": {},
   "source": [
    "* **Criando o Schema de validação do Pandera.**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42da5551-b58e-40cc-a605-3363b444cd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/utils/schema.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils/schema.py\n",
    "# Schema para validação \n",
    "import pandera as pa\n",
    "from pandera.typing import Series\n",
    "\n",
    "class VendasSchema(pa.SchemaModel):\n",
    "    Produto: Series[str]\n",
    "    Categoria: Series[str]\n",
    "    Quantidade: Series[int] = pa.Field(ge=0)  # ge=0 significa \"maior ou igual a 0\"\n",
    "    Venda: Series[int] = pa.Field(ge=0)\n",
    "    Data: Series[str]\n",
    "    \n",
    "    class Config:\n",
    "        coerce = True\n",
    "        strict = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2cdc6-4f14-4ded-be79-be103db78fe3",
   "metadata": {},
   "source": [
    "#### Documentação do VendasSchema\n",
    "\n",
    "O `VendasSchema` é uma classe definida na biblioteca Pandera que define um esquema para validar e limpar dados relacionados a vendas.\n",
    "\n",
    "##### Atributos:\n",
    "- `Produto`: Uma série de strings representando os nomes dos produtos.\n",
    "- `Categoria`: Uma série de strings representando as categorias dos produtos.\n",
    "- `Quantidade`: Uma série de inteiros representando a quantidade de produtos vendidos. Deve ser maior ou igual a 0.\n",
    "- `Venda`: Uma série de inteiros representando o valor de venda dos produtos. Deve ser maior ou igual a 0.\n",
    "- `Data`: Uma série de strings representando as datas das vendas.\n",
    "\n",
    "##### Configurações:\n",
    "- `coerce`: Define se os tipos de dados devem ser coercíveis (ou seja, convertidos automaticamente) para os tipos definidos no esquema. Neste caso, está definido como True.\n",
    "- `strict`: Define se a validação deve ser estrita, ou seja, se os dados devem corresponder exatamente ao esquema definido. Neste caso, está definido como True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838eb41-3ea1-4443-9e03-531a0fdc9c8b",
   "metadata": {},
   "source": [
    "* **Incorporando o decorator pandera ao script de etl**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e95aa60f-82a5-4cad-814c-af4c892e58fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/etl.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/etl.py\n",
    "# Desafio ETL\n",
    "import glob\n",
    "import os\n",
    "from typing import List\n",
    "#importando os decorators\n",
    "from utils.timer_decorator import timer\n",
    "from utils.log_decorator import log_decorator\n",
    "from utils.schema import VendasSchema\n",
    "import pandera as pa\n",
    "import pandas as pd\n",
    "\n",
    "@pa.check_output(VendasSchema)\n",
    "def ler_arquivos_json(path_origin: str) -> pd.DataFrame:\n",
    "    caminho_arquivos = os.path.join(path_origin, \"*.json\")\n",
    "    arquivos_json = glob.glob(caminho_arquivos)\n",
    "    if not arquivos_json:\n",
    "        raise ValueError(\"Nenhum arquivo JSON encontrado na pasta especificada.\")\n",
    "    dfs = [pd.read_json(arquivo) for arquivo in arquivos_json]\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def transformar_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Receita\"] = df[\"Quantidade\"] * df[\"Venda\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def carregar_dataframe(\n",
    "    df: pd.DataFrame, path_to_save: str, format_to_save: List[str]\n",
    ") -> None:\n",
    "    for formato in format_to_save:\n",
    "        if formato.lower() == \"csv\":\n",
    "            caminho_salvar_csv = path_to_save + \".csv\"\n",
    "            df.to_csv(caminho_salvar_csv, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_csv}'\")\n",
    "        elif formato.lower() == \"parquet\":\n",
    "            caminho_salvar_parquet = path_to_save + \".parquet\"\n",
    "            df.to_parquet(caminho_salvar_parquet, index=False)\n",
    "            print(f\"DataFrame salvo em '{caminho_salvar_parquet}'\")\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Formato especificado não suportado. Use 'csv' ou 'parquet'.\"\n",
    "            )\n",
    "            \n",
    "@log_decorator\n",
    "@timer\n",
    "def pipeline(path_origin: str, path_to_save: str, format_to_save: List[str]) -> None:\n",
    "    df = ler_arquivos_json(path_origin)\n",
    "    df = transformar_dataframe(df)\n",
    "    carregar_dataframe(df, path_to_save, format_to_save)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path_to_save = \"data/process/dados_processados\"\n",
    "    path_origin = \"data/\"\n",
    "    format_to_save = [\"csv\", \"parquet\"]  # ou 'parquet'\n",
    "\n",
    "    pipeline(path_origin, path_to_save, format_to_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bcaa0f-2e26-494f-ab07-5f9f7040c504",
   "metadata": {},
   "source": [
    "* **Execução da pipeline com o decorator pandera**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "810bfb8a-8acd-4c5d-929d-e2de4cc1ca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n",
      "2024-04-10T00:07:19.978725-0300 \u001b[31mINFO\u001b[0m \u001b[32mChamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {}\u001b[0m log_decorator.py\n",
      "DataFrame salvo em 'data/process/dados_processados.csv'\n",
      "DataFrame salvo em 'data/process/dados_processados.parquet'\n",
      "2024-04-10T00:07:20.042259-0300 \u001b[31mINFO\u001b[0m \u001b[32mFunction 'pipeline' executed in 0:00:00.063039\u001b[0m timer_decorator.py\n",
      "2024-04-10T00:07:20.042650-0300 \u001b[31mINFO\u001b[0m \u001b[32m'pipeline' retornou None\u001b[0m log_decorator.py\n"
     ]
    }
   ],
   "source": [
    "!python src/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d87f6f-efd5-43ca-88e1-dae58bed6687",
   "metadata": {},
   "source": [
    "* **Vamos acessar o log**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eac45baa-7532-4434-aa17-01fa5e1791b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load log/app.log\n",
    "2024-04-10T00:07:19.978725-0300 INFO Chamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {} log_decorator.py\n",
    "2024-04-10T00:07:20.042259-0300 INFO Function 'pipeline' executed in 0:00:00.063039 timer_decorator.py\n",
    "2024-04-10T00:07:20.042650-0300 INFO 'pipeline' retornou None log_decorator.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c43bed-65d7-4751-8048-b4201d385328",
   "metadata": {},
   "source": [
    "* **Veja que o todos os testes com o Pandera passaram.**\n",
    "* **Agora vamos simular um erro por exemplo, alguém digitou \"Produto\" com \"Product\" e ver se o erro acontece.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76025696-ae20-49b5-b68d-6832c7affb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data/coleta_dia03.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/coleta_dia03.json\n",
    "[\n",
    "    {\n",
    "        \"Prodct\": \"Notebook Gamer\",\n",
    "        \"Categoria\": \"Eletrônicos\",\n",
    "        \"Quantidade\": 2,\n",
    "        \"Venda\": 1500,\n",
    "        \"Data\": \"2023-01-17\"\n",
    "    },\n",
    "    {\n",
    "        \"Produto\": \"Mouse Sem Fio\",\n",
    "        \"Categoria\": \"Eletrônicos\",\n",
    "        \"Quantidade\": 14,\n",
    "        \"Venda\": 30,\n",
    "        \"Data\": \"2023-01-17\"\n",
    "    },\n",
    "    {\n",
    "        \"Produto\": \"Teclado Mecânico\",\n",
    "        \"Categoria\": \"Eletrônicos\",\n",
    "        \"Quantidade\": 2,\n",
    "        \"Venda\": 100,\n",
    "        \"Data\": \"2023-01-17\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4f611-82b6-41f8-ace8-deced2fa0cff",
   "metadata": {},
   "source": [
    "* **Agora vamos rodar o script**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27ac09-7657-402b-b922-0abdf331e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb4a019-8b33-4d42-8b7d-541f69818244",
   "metadata": {},
   "source": [
    "* **Vamos acessar o arquivo de log:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7b765c4-f792-4c51-a483-78cd4fee40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load log/app.log\n",
    "2024-04-10T00:07:19.978725-0300 INFO Chamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {} log_decorator.py\n",
    "2024-04-10T00:07:20.042259-0300 INFO Function 'pipeline' executed in 0:00:00.063039 timer_decorator.py\n",
    "2024-04-10T00:07:20.042650-0300 INFO 'pipeline' retornou None log_decorator.py\n",
    "2024-04-10T00:08:02.114924-0300 INFO Chamando 'pipeline' com ('data/', 'data/process/dados_processados', ['csv', 'parquet']) e {} log_decorator.py\n",
    "2024-04-10T00:08:02.137134-0300 ERROR 'pipeline' lançou uma exceção: error in check_output decorator of function 'ler_arquivos_json': column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(name=Categoria, type=DataType(str))>, 'Quantidade': <Schema Column(name=Quantidade, type=DataType(int64))>, 'Venda': <Schema Column(name=Venda, type=DataType(int64))>, 'Data': <Schema Column(name=Data, type=DataType(str))>} log_decorator.py\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py\", line 371, in _try_validate\n",
    "    return schema.validate(\n",
    "           │      └ <classmethod(<function DataFrameModel.validate at 0x7fafe0836680>)>\n",
    "           └ VendasSchema\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/pandas/model.py\", line 306, in validate\n",
    "    cls.to_schema().validate(\n",
    "    │   └ <classmethod(<function DataFrameModel.to_schema at 0x7fafe08364d0>)>\n",
    "    └ VendasSchema\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/pandas/container.py\", line 375, in validate\n",
    "    return self._validate(\n",
    "           │    └ <function DataFrameSchema._validate at 0x7fafe07e80d0>\n",
    "           └ <Schema DataFrameSchema(columns={'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(na...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/pandas/container.py\", line 404, in _validate\n",
    "    return self.get_backend(check_obj).validate(\n",
    "           │    │           └             Produto    Categoria  Quantidade  Venda        Data          Prodct\n",
    "           │    │             0    Notebook Gamer  Eletrônicos           3 ...\n",
    "           │    └ <classmethod(<function BaseSchema.get_backend at 0x7fafe07c5630>)>\n",
    "           └ <Schema DataFrameSchema(columns={'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(na...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/backends/pandas/container.py\", line 84, in validate\n",
    "    error_handler.collect_error(\n",
    "    │             └ <function ErrorHandler.collect_error at 0x7fafe08115a0>\n",
    "    └ <pandera.api.base.error_handler.ErrorHandler object at 0x7fafe08a5240>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/api/base/error_handler.py\", line 54, in collect_error\n",
    "    raise schema_error from original_exc\n",
    "          │                 └ None\n",
    "          └ SchemaError(\"column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/backends/pandas/container.py\", line 82, in validate\n",
    "    check_obj = parser(check_obj, *args)\n",
    "                │      │           └ (<Schema DataFrameSchema(columns={'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(n...\n",
    "                │      └             Produto    Categoria  Quantidade  Venda        Data          Prodct\n",
    "                │        0    Notebook Gamer  Eletrônicos           3 ...\n",
    "                └ <bound method DataFrameSchemaBackend.strict_filter_columns of <pandera.backends.pandas.container.DataFrameSchemaBackend objec...\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/backends/pandas/container.py\", line 492, in strict_filter_columns\n",
    "    raise SchemaError(\n",
    "          └ <class 'pandera.errors.SchemaError'>\n",
    "\n",
    "pandera.errors.SchemaError: column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(name=Categoria, type=DataType(str))>, 'Quantidade': <Schema Column(name=Quantidade, type=DataType(int64))>, 'Venda': <Schema Column(name=Venda, type=DataType(int64))>, 'Data': <Schema Column(name=Data, type=DataType(str))>}\n",
    "\n",
    "\n",
    "The above exception was the direct cause of the following exception:\n",
    "\n",
    "\n",
    "Traceback (most recent call last):\n",
    "\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/pipeline.py\", line 7, in <module>\n",
    "    pipeline(path_origin, path_to_save, format_to_save)\n",
    "    │        │            │             └ ['csv', 'parquet']\n",
    "    │        │            └ 'data/process/dados_processados'\n",
    "    │        └ 'data/'\n",
    "    └ <function pipeline at 0x7fafe089d240>\n",
    "\n",
    "> File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/log_decorator.py\", line 53, in wrapper\n",
    "    result = func(*args, **kwargs)\n",
    "             │     │       └ {}\n",
    "             │     └ ('data/', 'data/process/dados_processados', ['csv', 'parquet'])\n",
    "             └ <function pipeline at 0x7fafe089d1b0>\n",
    "\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/utils/timer_decorator.py\", line 10, in wrapper\n",
    "    result = func(*args, **kwargs)\n",
    "             │     │       └ {}\n",
    "             │     └ ('data/', 'data/process/dados_processados', ['csv', 'parquet'])\n",
    "             └ <function pipeline at 0x7fafe089d120>\n",
    "\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_08/src/etl.py\", line 47, in pipeline\n",
    "    df = ler_arquivos_json(path_origin)\n",
    "         │                 └ 'data/'\n",
    "         └ <FunctionWrapper at 0x7fafe086f0a0 for function at 0x7fafe089cca0>\n",
    "\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py\", line 424, in _wrapper\n",
    "    return validate(out, fn)\n",
    "           │        │    └ <function ler_arquivos_json at 0x7fafe089cca0>\n",
    "           │        └             Produto    Categoria  Quantidade  Venda        Data          Prodct\n",
    "           │          0    Notebook Gamer  Eletrônicos           3 ...\n",
    "           └ <function check_output.<locals>.validate at 0x7fb02d8cf9a0>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py\", line 378, in validate\n",
    "    return _try_validate(out)\n",
    "           │             └             Produto    Categoria  Quantidade  Venda        Data          Prodct\n",
    "           │               0    Notebook Gamer  Eletrônicos           3 ...\n",
    "           └ <function check_output.<locals>.validate.<locals>._try_validate at 0x7fb02d9a7d90>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py\", line 375, in _try_validate\n",
    "    _handle_schema_error(\"check_output\", fn, schema, obj, e)\n",
    "    │                                    │   │       └             Produto    Categoria  Quantidade  Venda        Data          Prodct\n",
    "    │                                    │   │         0    Notebook Gamer  Eletrônicos           3 ...\n",
    "    │                                    │   └ VendasSchema\n",
    "    │                                    └ <function ler_arquivos_json at 0x7fafe089cca0>\n",
    "    └ <function _handle_schema_error at 0x7fafe089c0d0>\n",
    "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/.venv/lib/python3.10/site-packages/pandera/decorators.py\", line 100, in _handle_schema_error\n",
    "    raise _parse_schema_error(\n",
    "          └ <function _parse_schema_error at 0x7fafe089c160>\n",
    "\n",
    "pandera.errors.SchemaError: error in check_output decorator of function 'ler_arquivos_json': column 'Prodct' not in DataFrameSchema {'Produto': <Schema Column(name=Produto, type=DataType(str))>, 'Categoria': <Schema Column(name=Categoria, type=DataType(str))>, 'Quantidade': <Schema Column(name=Quantidade, type=DataType(int64))>, 'Venda': <Schema Column(name=Venda, type=DataType(int64))>, 'Data': <Schema Column(name=Data, type=DataType(str))>}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7452852-dbc0-4168-b8b5-9da096176cf1",
   "metadata": {},
   "source": [
    "* **Veja que o log mostra exatamente a coluna que encontrou o erro de validação e não passou adiante.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe6e25-6db8-4358-acd1-86a0fb8e3c8b",
   "metadata": {},
   "source": [
    "* **Com isso conseguimos concluir que ao usar o Loguru e o Pandera como decorators é essencial para garantir a qualidade e monitoramento dos dados em aplicações Python. O Loguru permite um registro eficiente e flexível de eventos, facilitando a identificação e resolução de problemas. Enquanto isso, o Pandera oferece uma validação robusta de dados, garantindo a integridade e consistência dos mesmos. Juntos, esses decorators fornecem uma abordagem abrangente para garantir a qualidade dos dados e facilitar o monitoramento por meio de logs em caso de erros, contribuindo para a confiabilidade e eficiência das aplicações.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e17d0a-2b39-47fd-aa1c-f012f83ea49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
