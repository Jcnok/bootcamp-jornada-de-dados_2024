{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca9eda-4225-4d90-b562-7f9a13ede487",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298fa10-9391-46b8-a273-e9af01922cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84e768-edde-4dbe-8a7a-6090da4104fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Modelo simples para gerar dados aleatórios com faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c90fa0e-7ad7-4064-a07e-1f3ebce826af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite o número de linhas a serem geradas:  1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 1000000/1000000 [01:57<00:00, 8520.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo real de geração:1 minutos 57 segundos\n",
      "Tamanho real do arquivo: 17.36 Megabytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gera dados aleatórios \n",
    "import faker\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Cria um objeto Faker\n",
    "fake = faker.Faker()\n",
    "\n",
    "def format_time(segundos):\n",
    "    \"\"\"\n",
    "    Formata os milisegundos em hora:minuto:segundo\n",
    "    \"\"\"\n",
    "    if segundos < 60:\n",
    "        return f\"{segundos:.3f} segundos\"\n",
    "    elif segundos < 3600:\n",
    "        minutos, segundos = divmod(segundos, 60)\n",
    "        return f\"{int(minutos)} minutos {int(segundos)} segundos\"\n",
    "    else:\n",
    "        horas, remainder = divmod(seconds, 3600)\n",
    "        minutos, segundos = divmod(remainder, 60)\n",
    "        if minutos == 0:\n",
    "            return f\"{int(horas)} horas {int(segundos)} segundos\"\n",
    "        else:\n",
    "            return f\"{int(horas)} horas {int(minutos)} minutos {int(segundos)} segundos\"\n",
    "\n",
    "# Função para gerar os dados de teste\n",
    "def generate_test_data(num_rows):\n",
    "  \"\"\"\n",
    "  Gera dados de teste e os escreve em um arquivo.\n",
    "\n",
    "  Argumentos:\n",
    "    num_rows: Número de linhas a serem geradas.\n",
    "\n",
    "  Retorno:\n",
    "    None.\n",
    "  \"\"\"\n",
    "  with open(\"data/measurements1.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for _ in tqdm(range(num_rows)):\n",
    "      # Gera dados aleatórios\n",
    "      station_name = fake.city()\n",
    "      temperature = round(fake.random_element([random.uniform(-50, 50), random.uniform(50, 100)]), 1)\n",
    "\n",
    "      # Escreve a linha no arquivo\n",
    "      file.write(f\"{station_name};{temperature}\\n\")\n",
    "\n",
    "# Solicita o número de linhas ao usuário\n",
    "num_rows = int(input(\"Digite o número de linhas a serem geradas: \"))\n",
    "\n",
    "# Gera os dados de teste\n",
    "start_time = time.time()\n",
    "generate_test_data(num_rows)\n",
    "end_time = time.time()\n",
    "\n",
    "# Exibe o tempo real de geração\n",
    "tempo_em_segundos = end_time - start_time\n",
    "print(f\"Tempo real de geração:{format_time(tempo_em_segundos)}\")\n",
    "\n",
    "# Converte o tamanho do arquivo para megabytes\n",
    "file_size = os.path.getsize(\"data/measurements1.txt\")\n",
    "file_size_mb = file_size / (1024 * 1024)\n",
    "\n",
    "# Exibe o tamanho do arquivo em megabytes\n",
    "print(f\"Tamanho real do arquivo: {file_size_mb:.2f} Megabytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118380c-d98f-4c19-8f43-b504fafc9473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Modelo para gerar dados aleatórios com faker e multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd0d41e-45a8-4419-bbf0-171d132c7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite o número de linhas a serem geradas:  1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 100/100 [01:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo real de geração:1 minutos 47 segundos\n",
      "Tamanho real do arquivo: 17.36 Megabytes\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Cria um objeto Faker\n",
    "fake = faker.Faker()\n",
    "\n",
    "# Formata o tempo.\n",
    "def format_time(segundos):\n",
    "    \"\"\"\n",
    "    Formata os milisegundos em hora:minuto:segundo\n",
    "    \"\"\"\n",
    "    if segundos < 60:\n",
    "        return f\"{segundos:.3f} segundos\"\n",
    "    elif segundos < 3600:\n",
    "        minutos, segundos = divmod(segundos, 60)\n",
    "        return f\"{int(minutos)} minutos {int(segundos)} segundos\"\n",
    "    else:\n",
    "        horas, remainder = divmod(seconds, 3600)\n",
    "        minutos, segundos = divmod(remainder, 60)\n",
    "        if minutos == 0:\n",
    "            return f\"{int(horas)} horas {int(segundos)} segundos\"\n",
    "        else:\n",
    "            return f\"{int(horas)} horas {int(minutos)} minutos {int(segundos)} segundos\"\n",
    "\n",
    "# Função para gerar dados de teste\n",
    "def generate_test_data(num_rows, chunk_size):\n",
    "  \"\"\"\n",
    "  Gera dados de teste e os escreve em um arquivo.\n",
    "\n",
    "  Argumentos:\n",
    "    num_rows: Número de linhas a serem geradas.\n",
    "    chunk_size: Tamanho do bloco de dados a ser gerado por cada thread.\n",
    "\n",
    "  Retorno:\n",
    "    None.\n",
    "  \"\"\"\n",
    "  with open(\"data/measurements.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for i in tqdm(range(0, num_rows, chunk_size)):\n",
    "      # Gera um bloco de dados\n",
    "      data_chunk = []\n",
    "      for _ in range(chunk_size):\n",
    "        station_name = fake.city()\n",
    "        temperature = round(fake.random_element([random.uniform(-50, 50), random.uniform(50, 100)]), 1)\n",
    "        data_chunk.append(f\"{station_name};{temperature}\\n\")\n",
    "\n",
    "      # Escreve o bloco de dados no arquivo\n",
    "      file.writelines(data_chunk)\n",
    "\n",
    "# Solicita o número de linhas ao usuário\n",
    "num_rows = int(input(\"Digite o número de linhas a serem geradas: \"))\n",
    "\n",
    "# Define o tamanho do bloco de dados\n",
    "chunk_size = 10_000  # Ajuste este valor de acordo com a sua memória disponível\n",
    "\n",
    "# Número de threads\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "# Gera os dados de teste em paralelo\n",
    "start_time = time.time()\n",
    "with Pool(num_workers) as pool:\n",
    "  pool.starmap(generate_test_data, [(num_rows, chunk_size)])\n",
    "end_time = time.time()\n",
    "\n",
    "# Exibe o tempo real de geração\n",
    "tempo_em_segundos = end_time - start_time\n",
    "print(f\"Tempo real de geração:{format_time(tempo_em_segundos)}\")\n",
    "\n",
    "# Exibe o tamanho real do arquivo\n",
    "file_size = os.path.getsize(\"data/measurements.txt\")\n",
    "\n",
    "# Converte o tamanho do arquivo para megabytes\n",
    "file_size_mb = file_size / (1024 * 1024)\n",
    "\n",
    "# Exibe o tamanho do arquivo em megabytes\n",
    "print(f\"Tamanho real do arquivo: {file_size_mb:.2f} Megabytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274703a-146f-472d-a0fa-3fadebf510bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Scrip python para gerar dados aleatórios\n",
    "* **O script foi retirado do desafio [The One Billion Row Challenge](https://github.com/gunnarmorling/1brc), originalmente proposto para Java.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ff1f98-314d-4e04-8e10-28da8764ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/gunnarmorling/1brc/blob/main/src/main/java/dev/morling/onebrc/CreateMeasurements.java\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def check_args(file_args):\n",
    "    \"\"\"\n",
    "    Sanity checks out input and prints out usage if input is not a positive integer\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(file_args) != 2 or int(file_args[1]) <= 0:\n",
    "            raise Exception()\n",
    "    except:\n",
    "        print(\"Usage:  create_measurements.sh <positive integer number of records to create>\")\n",
    "        print(\"        You can use underscore notation for large number of records.\")\n",
    "        print(\"        For example:  1_000_000_000 for one billion\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "def build_weather_station_name_list():\n",
    "    \"\"\"\n",
    "    Grabs the weather station names from example data provided in repo and dedups\n",
    "    \"\"\"\n",
    "    station_names = []\n",
    "    with open('data/weather_stations.csv', 'r') as file:\n",
    "        file_contents = file.read()\n",
    "    for station in file_contents.splitlines():\n",
    "        if \"#\" in station:\n",
    "            next\n",
    "        else:\n",
    "            station_names.append(station.split(';')[0])\n",
    "    return list(set(station_names))\n",
    "\n",
    "\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    Convert bytes to a human-readable format (e.g., KiB, MiB, GiB)\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KiB', 'MiB', 'GiB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "\n",
    "def format_elapsed_time(seconds):\n",
    "    \"\"\"\n",
    "    Format elapsed time in a human-readable format\n",
    "    \"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.3f} seconds\"\n",
    "    elif seconds < 3600:\n",
    "        minutes, seconds = divmod(seconds, 60)\n",
    "        return f\"{int(minutes)} minutes {int(seconds)} seconds\"\n",
    "    else:\n",
    "        hours, remainder = divmod(seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        if minutes == 0:\n",
    "            return f\"{int(hours)} hours {int(seconds)} seconds\"\n",
    "        else:\n",
    "            return f\"{int(hours)} hours {int(minutes)} minutes {int(seconds)} seconds\"\n",
    "\n",
    "\n",
    "def estimate_file_size(weather_station_names, num_rows_to_create):\n",
    "    \"\"\"\n",
    "    Tries to estimate how large a file the test data will be\n",
    "    \"\"\"\n",
    "    total_name_bytes = sum(len(s.encode(\"utf-8\")) for s in weather_station_names)\n",
    "    avg_name_bytes = total_name_bytes / float(len(weather_station_names))\n",
    "\n",
    "    # avg_temp_bytes = sum(len(str(n / 10.0)) for n in range(-999, 1000)) / 1999\n",
    "    avg_temp_bytes = 4.400200100050025\n",
    "\n",
    "    # add 2 for separator and newline\n",
    "    avg_line_length = avg_name_bytes + avg_temp_bytes + 2\n",
    "\n",
    "    human_file_size = convert_bytes(num_rows_to_create * avg_line_length)\n",
    "\n",
    "    return f\"Estimated max file size is:  {human_file_size}.\"\n",
    "\n",
    "\n",
    "def build_test_data(weather_station_names, num_rows_to_create):\n",
    "    \"\"\"\n",
    "    Generates and writes to file the requested length of test data\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    coldest_temp = -99.9\n",
    "    hottest_temp = 99.9\n",
    "    station_names_10k_max = random.choices(weather_station_names, k=10_000)\n",
    "    batch_size = 10000 # instead of writing line by line to file, process a batch of stations and put it to disk\n",
    "    chunks = num_rows_to_create // batch_size\n",
    "    print('Building test data...')\n",
    "\n",
    "    try:\n",
    "        with open(\"data/measurements1.txt\", 'w') as file:\n",
    "            progress = 0\n",
    "            for chunk in range(chunks):\n",
    "                \n",
    "                batch = random.choices(station_names_10k_max, k=batch_size)\n",
    "                prepped_deviated_batch = '\\n'.join([f\"{station};{random.uniform(coldest_temp, hottest_temp):.1f}\" for station in batch]) # :.1f should quicker than round on a large scale, because round utilizes mathematical operation\n",
    "                file.write(prepped_deviated_batch + '\\n')\n",
    "                \n",
    "                # Update progress bar every 1%\n",
    "                if (chunk + 1) * 100 // chunks != progress:\n",
    "                    progress = (chunk + 1) * 100 // chunks\n",
    "                    bars = '=' * (progress // 2)\n",
    "                    sys.stdout.write(f\"\\r[{bars:<50}] {progress}%\")\n",
    "                    sys.stdout.flush()\n",
    "        sys.stdout.write('\\n')\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong. Printing error info and exiting...\")\n",
    "        print(e)\n",
    "        exit()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    file_size = os.path.getsize(\"data/measurements1.txt\")\n",
    "    human_file_size = convert_bytes(file_size)\n",
    " \n",
    "    print(\"Test data successfully written to data/measurements1.txt\")\n",
    "    print(f\"Actual file size:  {human_file_size}\")\n",
    "    print(f\"Elapsed time: {format_elapsed_time(elapsed_time)}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    main program function\n",
    "    \"\"\"\n",
    "    num_rows_to_create = 1_000_000\n",
    "    weather_station_names = []\n",
    "    weather_station_names = build_weather_station_name_list()\n",
    "    print(estimate_file_size(weather_station_names, num_rows_to_create))\n",
    "    build_test_data(weather_station_names, num_rows_to_create)\n",
    "    print(\"Test data build complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73194a23-2a9e-44f0-a8b2-1317bb3f6536",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "* **O modelo para gerar dados com o faker se saiu extremamente lento em comparação ao script do [Gunnar Morling](https://github.com/gunnarmorling) acima.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b4f57-8c2e-4cb2-941b-526d10fd663e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gerando 1 bilhão de linhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd9fccf3-871e-44e0-8089-406a476b40ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated max file size is:  14.8 GiB.\n",
      "Building test data...\n",
      "[==================================================] 100%\n",
      "Test data successfully written to data/measurements.txt\n",
      "Actual file size:  14.9 GiB\n",
      "Elapsed time: 15 minutes 3 seconds\n",
      "Test data build complete.\n"
     ]
    }
   ],
   "source": [
    "# gerando 1 bilhão de linhas\n",
    "num_rows_to_create = 1_000_000_000\n",
    "weather_station_names = []\n",
    "weather_station_names = build_weather_station_name_list()\n",
    "print(estimate_file_size(weather_station_names, num_rows_to_create))\n",
    "build_test_data(weather_station_names, num_rows_to_create)\n",
    "print(\"Test data build complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7b87b-9ff0-4e17-bac4-ec9dc191add3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Decoradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c4b55b-6d4d-4094-b518-f99a45da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um decorator para calcular o tempo de processamento\n",
    "def timer(func):\n",
    "    import time\n",
    "    # Formata o tempo.\n",
    "    def format_time(segundos: int): \n",
    "        \"\"\"\n",
    "        Formata os milisegundos em hora:minuto:segundo\n",
    "        \"\"\"\n",
    "        if segundos < 60:\n",
    "            return f\"{segundos:.3f} segundos\"\n",
    "        elif segundos < 3600:\n",
    "            minutos, segundos = divmod(segundos, 60)\n",
    "            return f\"{int(minutos)} minutos {int(segundos)} segundos\"\n",
    "        else:\n",
    "            horas, remainder = divmod(seconds, 3600)\n",
    "            minutos, segundos = divmod(remainder, 60)\n",
    "            if minutos == 0:\n",
    "                return f\"{int(horas)} horas {int(segundos)} segundos\"\n",
    "            else:\n",
    "                return f\"{int(horas)} horas {int(minutos)} minutos {int(segundos)} segundos\"  \n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        tempo_em_segundos = end - start       \n",
    "        # Exibe o tempo real de geração    \n",
    "        print(f\"{func.__name__} Tempo de processamento:{format_time(tempo_em_segundos)}\")   \n",
    "        #print(type(format_time(tempo_em_segundos)))\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c14b73-eeef-4545-a1aa-11f872ae2d6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pandas - min, max e mean em 1 bilhão de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac2551-f634-411a-bafe-70ceb59bdb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando a lib pandas.\n",
    "!poetry add pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606ee748-4d0c-4532-b835-cee92cde5a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o processamento do arquivo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando:  60%|█████████████████████████▏                | 6/10 [05:24<03:40, 55.25s/it]IOStream.flush timed out\n",
      "Processando:  70%|█████████████████████████████▍            | 7/10 [06:20<02:46, 55.35s/it]IOStream.flush timed out\n",
      "Processando:  90%|█████████████████████████████████████▊    | 9/10 [08:11<00:55, 55.40s/it]IOStream.flush timed out\n",
      "Processando: 100%|█████████████████████████████████████████| 10/10 [09:20<00:00, 56.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       station   min   max      mean\n",
      "0     Aabenraa -99.9  99.9 -0.061535\n",
      "1       Aalten -99.9  99.9 -0.161205\n",
      "2    Abadiânia -99.9  99.9 -0.051514\n",
      "3     Abalessa -99.9  99.9  0.211034\n",
      "4  Abangaritos -99.9  99.9  0.066196\n",
      "Tempo de processamento:-1709939632.573 segundos\n"
     ]
    }
   ],
   "source": [
    "# Script para min, max e mean de um bilhão de linhas com pandas.\n",
    "import pandas as pd\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm  # importa o tqdm para barra de progresso\n",
    "\n",
    "CONCURRENCY = cpu_count()\n",
    "\n",
    "total_linhas = 1_000_000_000  # Total de linhas conhecido\n",
    "chunksize = 100_000_000  # Define o tamanho do chunk\n",
    "filename = \"data/measurements.txt\"  # Certifique-se de que este é o caminho correto para o arquivo\n",
    "\n",
    "# Formata o tempo.\n",
    "def format_time(segundos):\n",
    "    \"\"\"\n",
    "    Formata os milisegundos em hora:minuto:segundo\n",
    "    \"\"\"\n",
    "    if segundos < 60:\n",
    "        return f\"{segundos:.3f} segundos\"\n",
    "    elif segundos < 3600:\n",
    "        minutos, segundos = divmod(segundos, 60)\n",
    "        return f\"{int(minutos)} minutos {int(segundos)} segundos\"\n",
    "    else:\n",
    "        horas, remainder = divmod(seconds, 3600)\n",
    "        minutos, segundos = divmod(remainder, 60)\n",
    "        if minutos == 0:\n",
    "            return f\"{int(horas)} horas {int(segundos)} segundos\"\n",
    "        else:\n",
    "            return f\"{int(horas)} horas {int(minutos)} minutos {int(segundos)} segundos\"\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    # Agrega os dados dentro do chunk usando Pandas\n",
    "    aggregated = chunk.groupby('station')['measure'].agg(['min', 'max', 'mean']).reset_index()\n",
    "    return aggregated\n",
    "\n",
    "def create_df_with_pandas(filename, total_linhas, chunksize=chunksize):\n",
    "    total_chunks = total_linhas // chunksize + (1 if total_linhas % chunksize else 0)\n",
    "    results = []\n",
    "\n",
    "    with pd.read_csv(filename, sep=';', header=None, names=['station', 'measure'], chunksize=chunksize) as reader:\n",
    "        # Envolvendo o iterador com tqdm para visualizar o progresso\n",
    "        with Pool(CONCURRENCY) as pool:\n",
    "            for chunk in tqdm(reader, total=total_chunks, desc=\"Processando\"):\n",
    "                # Processa cada chunk em paralelo\n",
    "                result = pool.apply_async(process_chunk, (chunk,))\n",
    "                results.append(result)\n",
    "\n",
    "            results = [result.get() for result in results]\n",
    "\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    final_aggregated_df = final_df.groupby('station').agg({\n",
    "        'min': 'min',\n",
    "        'max': 'max',\n",
    "        'mean': 'mean'\n",
    "    }).reset_index().sort_values('station')\n",
    "\n",
    "    return final_aggregated_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "\n",
    "    print(\"Iniciando o processamento do arquivo.\")\n",
    "    start_time = time.time()\n",
    "    df = create_df_with_pandas(filename, total_linhas, chunksize)\n",
    "    end_time = time.time()\n",
    "    tempo_em_segundos = end_time - start_time\n",
    "    print(df.head())\n",
    "    # Exibe o tempo real de geração    \n",
    "    print(f\"Tempo de processamento:{format_time(tempo_em_segundos)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be5f4c-6870-4f2b-8403-3e4751da0eb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Polars - min, max e mean em 1 bilhão de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622fcb8-9f8f-4b34-bf90-e491ccf0bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando a lib polars\n",
    "!poetry add polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31de0d4-931d-4fd3-8353-373c41062cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_polars_df Tempo de processamento:26.558 segundos\n",
      "shape: (8_836, 4)\n",
      "┌────────────────┬──────────┬──────────┬───────────┐\n",
      "│ station        ┆ max_temp ┆ min_temp ┆ mean_temp │\n",
      "│ ---            ┆ ---      ┆ ---      ┆ ---       │\n",
      "│ str            ┆ f64      ┆ f64      ┆ f64       │\n",
      "╞════════════════╪══════════╪══════════╪═══════════╡\n",
      "│ Aabenraa       ┆ 99.9     ┆ -99.9    ┆ -0.062295 │\n",
      "│ Aalten         ┆ 99.9     ┆ -99.9    ┆ -0.161752 │\n",
      "│ Abadiânia      ┆ 99.9     ┆ -99.9    ┆ -0.052772 │\n",
      "│ Abalessa       ┆ 99.9     ┆ -99.9    ┆ 0.211089  │\n",
      "│ Abangaritos    ┆ 99.9     ┆ -99.9    ┆ 0.063772  │\n",
      "│ …              ┆ …        ┆ …        ┆ …         │\n",
      "│ ’Aïn Abessa    ┆ 99.9     ┆ -99.9    ┆ -0.013338 │\n",
      "│ ’Aïn Azel      ┆ 99.9     ┆ -99.9    ┆ -0.040762 │\n",
      "│ ’Aïn Roua      ┆ 99.9     ┆ -99.9    ┆ -0.026898 │\n",
      "│ ’s-Gravenzande ┆ 99.9     ┆ -99.9    ┆ -0.080973 │\n",
      "│ ’s-Heerenberg  ┆ 99.9     ┆ -99.9    ┆ 0.168265  │\n",
      "└────────────────┴──────────┴──────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "@timer\n",
    "def create_polars_df(): \n",
    "    pl.Config.set_streaming_chunk_size(5000000)\n",
    "    # Leitura do arquivo CSV e definição do schema\n",
    "    return (pl.scan_csv(\"data/measurements.txt\", separator=\";\", has_header=False,\n",
    "                        schema={\"station\": pl.String, \"measure\": pl.Float64})\n",
    "                        .group_by(\"station\").agg(\n",
    "                                                 max_temp=pl.col(\"measure\").max(),\n",
    "                                                 min_temp=pl.col(\"measure\").min(),\n",
    "                                                 mean_temp=pl.col(\"measure\").mean()\n",
    "                                                ).sort(\"station\").collect(streaming=True)\n",
    "           )   \n",
    "if __name__ == \"__main__\":    \n",
    "    df = create_polars_df()\n",
    "    print(df)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0fc93-52a7-4a33-9529-a3e8e78241c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Duckdb - min, max e mean em 1 bilhão de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4123a-14a4-4fd8-9336-c1a0dc1ab3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60de2ece-ec1b-4e06-8e50-9569efd1f1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e73372ad3b1479696fda6d952208310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────┬─────────────────┬──────────────────┬─────────────────┐\n",
      "│     station     │ min_temperature │ mean_temperature │ max_temperature │\n",
      "│     varchar     │  decimal(18,3)  │  decimal(18,3)   │  decimal(18,3)  │\n",
      "├─────────────────┼─────────────────┼──────────────────┼─────────────────┤\n",
      "│ Aabenraa        │         -99.900 │           -0.062 │          99.900 │\n",
      "│ Aalten          │         -99.900 │           -0.162 │          99.900 │\n",
      "│ Abadiânia       │         -99.900 │           -0.053 │          99.900 │\n",
      "│ Abalessa        │         -99.900 │            0.211 │          99.900 │\n",
      "│ Abangaritos     │         -99.900 │            0.064 │          99.900 │\n",
      "│ Abano Terme     │         -99.900 │            0.172 │          99.900 │\n",
      "│ Abaré           │         -99.900 │           -0.267 │          99.900 │\n",
      "│ Abbeville       │         -99.900 │            0.074 │          99.900 │\n",
      "│ Abbiategrasso   │         -99.900 │           -0.195 │          99.900 │\n",
      "│ Abbots Langley  │         -99.900 │            0.207 │          99.900 │\n",
      "│     ·           │            ·    │              ·   │             ·   │\n",
      "│     ·           │            ·    │              ·   │             ·   │\n",
      "│     ·           │            ·    │              ·   │             ·   │\n",
      "│ ‘Ajab Shīr      │         -99.900 │           -0.037 │          99.900 │\n",
      "│ ‘Ajmān          │         -99.900 │           -0.054 │          99.900 │\n",
      "│ ‘Akko           │         -99.900 │            0.156 │          99.900 │\n",
      "│ ‘Izbat al Burj  │         -99.900 │            0.172 │          99.900 │\n",
      "│ ’Ayn Bni Mathar │         -99.900 │           -0.102 │          99.900 │\n",
      "│ ’Aïn Abessa     │         -99.900 │           -0.013 │          99.900 │\n",
      "│ ’Aïn Azel       │         -99.900 │           -0.041 │          99.900 │\n",
      "│ ’Aïn Roua       │         -99.900 │           -0.027 │          99.900 │\n",
      "│ ’s-Gravenzande  │         -99.900 │           -0.081 │          99.900 │\n",
      "│ ’s-Heerenberg   │         -99.900 │            0.168 │          99.900 │\n",
      "├─────────────────┴─────────────────┴──────────────────┴─────────────────┤\n",
      "│ 8836 rows (20 shown)                                         4 columns │\n",
      "└────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "create_duckdb Tempo de processamento:18.208 segundos\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "@timer\n",
    "def create_duckdb():\n",
    "    duckdb.sql(\"\"\"\n",
    "        SELECT station,\n",
    "            MIN(measure) AS min_temperature,\n",
    "            CAST(AVG(measure) AS DECIMAL()) AS mean_temperature,\n",
    "            MAX(measure) AS max_temperature\n",
    "        FROM read_csv(\"data/measurements.txt\", AUTO_DETECT=FALSE, sep=';', columns={'station':VARCHAR, 'measure': 'DECIMAL'})\n",
    "        GROUP BY station\n",
    "        ORDER BY station\n",
    "    \"\"\").show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_duckdb()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d06b82-0eb9-4580-9d56-1588a191dc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5af59667b949d2a5e655c28442779d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>mean_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aabenraa</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aalten</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abadiânia</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abalessa</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>0.211</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abangaritos</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>0.064</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8831</th>\n",
       "      <td>’Aïn Abessa</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832</th>\n",
       "      <td>’Aïn Azel</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8833</th>\n",
       "      <td>’Aïn Roua</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8834</th>\n",
       "      <td>’s-Gravenzande</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>’s-Heerenberg</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>0.168</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             station  min_temperature  mean_temperature  max_temperature\n",
       "0           Aabenraa            -99.9            -0.062             99.9\n",
       "1             Aalten            -99.9            -0.162             99.9\n",
       "2          Abadiânia            -99.9            -0.053             99.9\n",
       "3           Abalessa            -99.9             0.211             99.9\n",
       "4        Abangaritos            -99.9             0.064             99.9\n",
       "...              ...              ...               ...              ...\n",
       "8831     ’Aïn Abessa            -99.9            -0.013             99.9\n",
       "8832       ’Aïn Azel            -99.9            -0.041             99.9\n",
       "8833       ’Aïn Roua            -99.9            -0.027             99.9\n",
       "8834  ’s-Gravenzande            -99.9            -0.081             99.9\n",
       "8835   ’s-Heerenberg            -99.9             0.168             99.9\n",
       "\n",
       "[8836 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_duckdb Tempo de processamento:19.675 segundos\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "@timer\n",
    "def create_duckdb(): \n",
    "    conn = duckdb.connect(':memory:')\n",
    "    start_time = time.time()\n",
    "    display(conn.execute(\"\"\"\n",
    "            SELECT station,\n",
    "                MIN(measure) AS min_temperature,\n",
    "                CAST(AVG(measure) AS DECIMAL()) AS mean_temperature,\n",
    "                MAX(measure) AS max_temperature\n",
    "            FROM read_csv(\"data/measurements.txt\", AUTO_DETECT=FALSE, sep=';', columns={'station':VARCHAR, 'measure': 'DECIMAL'})\n",
    "            GROUP BY station\n",
    "            ORDER BY station\n",
    "        \"\"\").df())\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    create_duckdb()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b56db18-3681-43c0-b1d8-f85dc0c5a001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>measurements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name\n",
       "0  measurements"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(conn.execute('SHOW TABLES').df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e60b76-b8bd-4d71-a747-766149ec8fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uppalapādu</td>\n",
       "      <td>-29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kaman</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamu</td>\n",
       "      <td>-40.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quillabamba</td>\n",
       "      <td>50.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jabuticabal</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kilibo</td>\n",
       "      <td>-98.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tillaivilāgam</td>\n",
       "      <td>48.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensenada</td>\n",
       "      <td>97.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indio</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Buxton</td>\n",
       "      <td>-54.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         station  measure\n",
       "0     Uppalapādu    -29.9\n",
       "1          Kaman    -34.0\n",
       "2           Tamu    -40.2\n",
       "3    Quillabamba     50.6\n",
       "4    Jabuticabal     15.8\n",
       "5         Kilibo    -98.4\n",
       "6  Tillaivilāgam     48.3\n",
       "7       Ensenada     97.4\n",
       "8          Indio     64.6\n",
       "9         Buxton    -54.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(conn.execute('Select * from measurements limit 10').df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06f0f088-a242-494f-a82a-d23ab44fac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a87d1-37ef-4def-960f-1e885b6008cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dask - min, max e mean em 1 bilhão de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd03e5-8f9e-4f2c-9397-91d7fc3dfc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessário Instalar.\n",
    "!pip install dask-expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f02dcf6-7633-4b3a-b68e-4d7a9c50a810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">measure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aabenraa</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.062295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aalten</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.161752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abadiânia</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.052772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abalessa</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>0.211089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abangaritos</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>0.063772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’Aïn Abessa</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.013338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’Aïn Azel</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.040762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’Aïn Roua</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.026898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’s-Gravenzande</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>-0.080973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’s-Heerenberg</th>\n",
       "      <td>99.9</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>0.168265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               measure                \n",
       "                   max   min      mean\n",
       "station                               \n",
       "Aabenraa          99.9 -99.9 -0.062295\n",
       "Aalten            99.9 -99.9 -0.161752\n",
       "Abadiânia         99.9 -99.9 -0.052772\n",
       "Abalessa          99.9 -99.9  0.211089\n",
       "Abangaritos       99.9 -99.9  0.063772\n",
       "...                ...   ...       ...\n",
       "’Aïn Abessa       99.9 -99.9 -0.013338\n",
       "’Aïn Azel         99.9 -99.9 -0.040762\n",
       "’Aïn Roua         99.9 -99.9 -0.026898\n",
       "’s-Gravenzande    99.9 -99.9 -0.080973\n",
       "’s-Heerenberg     99.9 -99.9  0.168265\n",
       "\n",
       "[8836 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_dask Tempo de processamento:7 minutos 41 segundos\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd\n",
    "@timer\n",
    "def create_dask():    \n",
    "    # Ler o arquivo txt diretamente em um DataFrame Dask\n",
    "    df = dd.read_csv('data/measurements.txt', delimiter=';', header=None, names=['station', 'measure'])\n",
    "    # min, max, e mean pela cidade ordenado pelo index\n",
    "    return display(df.groupby('station').agg({'measure': ['max','min','mean']}).compute().sort_index())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dask()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260f2322-7eb5-429b-bd4d-c8ffddbe6325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               measure                \n",
      "                   max   min      mean\n",
      "station                               \n",
      "Aabenraa          99.9 -99.9 -0.062295\n",
      "Aalten            99.9 -99.9 -0.161752\n",
      "Abadiânia         99.9 -99.9 -0.052772\n",
      "Abalessa          99.9 -99.9  0.211089\n",
      "Abangaritos       99.9 -99.9  0.063772\n",
      "...                ...   ...       ...\n",
      "’Aïn Abessa       99.9 -99.9 -0.013338\n",
      "’Aïn Azel         99.9 -99.9 -0.040762\n",
      "’Aïn Roua         99.9 -99.9 -0.026898\n",
      "’s-Gravenzande    99.9 -99.9 -0.080973\n",
      "’s-Heerenberg     99.9 -99.9  0.168265\n",
      "\n",
      "[8836 rows x 3 columns]\n",
      "create_dask Tempo de processamento:7 minutos 47 segundos\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd\n",
    "@timer\n",
    "def create_dask():    \n",
    "    # Ler o arquivo txt diretamente em um DataFrame Dask\n",
    "    df = dd.read_csv('data/measurements.txt', delimiter=';', header=None, names=['station', 'measure'])\n",
    "    # min, max, e mean pela cidade ordenado pelo index\n",
    "    print(df.groupby('station').\n",
    "    agg({'measure': ['max','min','mean']}).\n",
    "    compute().\n",
    "    sort_index())\n",
    "if __name__ == \"__main__\":\n",
    "    create_dask() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d595f9-cc87-4855-b977-1cc10cab90c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6d5a641-c514-4c94-a368-64424d857d9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pyspark - min, max e mean em 1 bilhão de linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f73b4-0590-48b2-9bce-0409c9aea24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalação da lib\n",
    "!poetry add pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3950ab52-82b6-4f9a-8a6b-d9afefc2aa67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:======================================================>(118 + 1) / 119]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+---------------+--------------------+\n",
      "|          City|Min Temperature|Max Temperature|     Avg Temperature|\n",
      "+--------------+---------------+---------------+--------------------+\n",
      "|      Aabenraa|          -99.9|           99.9| -0.0622947488794981|\n",
      "|        Aalten|          -99.9|           99.9|-0.16175193009676553|\n",
      "|     Abadiânia|          -99.9|           99.9|-0.05277215372419822|\n",
      "|      Abalessa|          -99.9|           99.9| 0.21108941553593294|\n",
      "|   Abangaritos|          -99.9|           99.9| 0.06377211310947027|\n",
      "|   Abano Terme|          -99.9|           99.9| 0.17194244350252394|\n",
      "|         Abaré|          -99.9|           99.9| -0.2666045273852838|\n",
      "|     Abbeville|          -99.9|           99.9| 0.07425508222933982|\n",
      "| Abbiategrasso|          -99.9|           99.9|-0.19547850239845785|\n",
      "|Abbots Langley|          -99.9|           99.9| 0.20737068497627278|\n",
      "|      Abdulino|          -99.9|           99.9|  0.1269626020386111|\n",
      "|      Aberdare|          -99.9|           99.9|-0.10531290191095477|\n",
      "|   Aberystwyth|          -99.9|           99.9| -0.1610037180650041|\n",
      "|       Abidjan|          -99.9|           99.9| 0.21977946705104265|\n",
      "|        Abinsk|          -99.9|           99.9|-0.11314484812510645|\n",
      "|         Abram|          -99.9|           99.9|-0.03221989738014504|\n",
      "|      Abrantes|          -99.9|           99.9| 0.16961210453744585|\n",
      "|     Abu Dhabi|          -99.9|           99.9|   0.225045139297893|\n",
      "|         Aburi|          -99.9|           99.9|0.012415769482142035|\n",
      "| Abī al Khaşīb|          -99.9|           99.9| 0.45014594150587645|\n",
      "+--------------+---------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "create_pyspark Tempo de processamento:2 minutos 52 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, min as spark_min, max as spark_max, avg as spark_avg\n",
    "@timer\n",
    "def create_pyspark():     \n",
    "    # Inicializar uma sessão Spark\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Temperature Analysis\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Ler o arquivo CSV diretamente em um DataFrame Spark\n",
    "    df = spark.read.option(\"header\", \"false\").option(\"delimiter\", \";\").csv(\"data/measurements.txt\") \\\n",
    "        .toDF(\"City\", \"Temperature\")\n",
    "    \n",
    "    # Converter a coluna 'Temperature' para tipo numérico\n",
    "    df = df.withColumn(\"Temperature\", col(\"Temperature\").cast(\"float\"))\n",
    "    \n",
    "    # Calcular estatísticas usando Spark SQL\n",
    "    statistics = df.groupBy(\"City\") \\\n",
    "        .agg(spark_min(\"Temperature\").alias(\"Min Temperature\"),\n",
    "             spark_max(\"Temperature\").alias(\"Max Temperature\"),\n",
    "             spark_avg(\"Temperature\").alias(\"Avg Temperature\"))\n",
    "    \n",
    "    # Ordenar as estatísticas pela cidade\n",
    "    statistics_sorted = statistics.orderBy(\"City\")\n",
    "    \n",
    "    # Mostrar as estatísticas\n",
    "    return statistics_sorted.show()\n",
    "    \n",
    "    # Encerrar a sessão Spark\n",
    "    # spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_pyspark()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2b54f-3cd0-4b33-9781-e1b2a8a2c66d",
   "metadata": {},
   "source": [
    "## Vaex - min, max e mean em 1 bilhão de linhas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0111eb8-99c0-46a2-a91a-b8378f7ddbf0",
   "metadata": {},
   "source": [
    "* **Para utilizar o Vaex foi necessário selecionar outro kernel com python 3.10.13.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2e662f-d655-4479-85d8-595a8d1455df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e88e530-d5f4-4199-98db-29cb1184a0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#        city                temperature\n",
      "0        West Pamela         -44.1\n",
      "1        New Ashley          -47.9\n",
      "2        Port Cody           -46.8\n",
      "3        Christianfurt       -42.9\n",
      "4        South Debbietown    17.5\n",
      "...      ...                 ...\n",
      "274,081  North Rosestad      67.1\n",
      "274,082  South Blakeborough  46.2\n",
      "274,083  Port Normachester   -5.1\n",
      "274,084  South Kentbury      -27.3\n",
      "274,085  North Katrinaville  67.8\n",
      "Execution time: 00:00:01.49\n"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "import time\n",
    "\n",
    "def main(filename):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Leitura do arquivo CSV utilizando Vaex\n",
    "    df = vaex.from_csv(filename, names=['city', 'temperature'], sep=';')\n",
    "\n",
    "    # Cálculo das estatísticas\n",
    "    min_temperature = df.groupby(df['city']).agg({'temperature': 'min'})\n",
    "    max_temperature = df.groupby(df['city']).agg({'temperature': 'max'})\n",
    "    mean_temperature = df.groupby(df['city']).agg({'temperature': 'mean'})\n",
    "\n",
    "    # Concatenação dos resultados\n",
    "    combined_results = vaex.concat([min_temperature, max_temperature, mean_temperature])\n",
    "    combined_results.columns = ['min_temperature', 'max_temperature', 'mean_temperature']\n",
    "\n",
    "    # Exibição dos resultados\n",
    "    print(combined_results)\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {format_time(execution_time)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"data/measurements1.txt\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc87d1a2-852f-4c65-bd6e-215faf967407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                                 </th><th>station          </th><th>measure_min  </th><th>measure_max  </th><th>measure_mean      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i>     </td><td>West Pamela      </td><td>-44.1        </td><td>95.4         </td><td>38.80804597701149 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i>     </td><td>New Ashley       </td><td>-47.9        </td><td>99.8         </td><td>39.13777777777778 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i>     </td><td>Port Cody        </td><td>-46.8        </td><td>99.0         </td><td>37.87761194029851 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i>     </td><td>Christianfurt    </td><td>-42.9        </td><td>99.7         </td><td>46.25333333333334 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i>     </td><td>South Debbietown </td><td>17.5         </td><td>99.1         </td><td>56.633333333333326</td></tr>\n",
       "<tr><td>...                               </td><td>...              </td><td>...          </td><td>...          </td><td>...               </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>91,357</i></td><td>West Lawrencestad</td><td>63.4         </td><td>67.8         </td><td>65.6              </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>91,358</i></td><td>East Tomburgh    </td><td>30.9         </td><td>30.9         </td><td>30.9              </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>91,359</i></td><td>West Savannahfurt</td><td>66.4         </td><td>66.4         </td><td>66.4              </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>91,360</i></td><td>Cristianberg     </td><td>2.0          </td><td>2.0          </td><td>2.0               </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>91,361</i></td><td>South Geraldbury </td><td>-26.2        </td><td>-26.2        </td><td>-26.2             </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "#       station            measure_min    measure_max    measure_mean\n",
       "0       West Pamela        -44.1          95.4           38.80804597701149\n",
       "1       New Ashley         -47.9          99.8           39.13777777777778\n",
       "2       Port Cody          -46.8          99.0           37.87761194029851\n",
       "3       Christianfurt      -42.9          99.7           46.25333333333334\n",
       "4       South Debbietown   17.5           99.1           56.633333333333326\n",
       "...     ...                ...            ...            ...\n",
       "91,357  West Lawrencestad  63.4           67.8           65.6\n",
       "91,358  East Tomburgh      30.9           30.9           30.9\n",
       "91,359  West Savannahfurt  66.4           66.4           66.4\n",
       "91,360  Cristianberg       2.0            2.0            2.0\n",
       "91,361  South Geraldbury   -26.2          -26.2          -26.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_vaex Tempo de processamento:1.453 segundos\n"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "@timer\n",
    "def create_vaex(filename):\n",
    "    # Leitura do arquivo CSV utilizando Vaex\n",
    "    df = vaex.from_csv(filename, names=['station', 'measure'], sep=';')\n",
    "\n",
    "    # Cálculo das estatísticas\n",
    "    combined_results = df.groupby(df['station']).agg({'measure': ['min', 'max', 'mean']})\n",
    "\n",
    "    # Exibição dos resultados\n",
    "    return display(combined_results)\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"data/measurements1.txt\"\n",
    "    create_vaex(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb494d83-fade-4295-9c41-7f96103f6983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting csv to chunk files\n",
      "Saved chunk #0 to data/measurements.txt_chunk_0.hdf5\n",
      "Saved chunk #1 to data/measurements.txt_chunk_1.hdf5\n",
      "Saved chunk #2 to data/measurements.txt_chunk_2.hdf5\n",
      "Saved chunk #3 to data/measurements.txt_chunk_3.hdf5\n",
      "Saved chunk #4 to data/measurements.txt_chunk_4.hdf5\n",
      "Saved chunk #5 to data/measurements.txt_chunk_5.hdf5\n",
      "Saved chunk #6 to data/measurements.txt_chunk_6.hdf5\n",
      "Saved chunk #7 to data/measurements.txt_chunk_7.hdf5\n",
      "Saved chunk #8 to data/measurements.txt_chunk_8.hdf5\n",
      "Saved chunk #9 to data/measurements.txt_chunk_9.hdf5\n",
      "Saved chunk #10 to data/measurements.txt_chunk_10.hdf5\n",
      "Saved chunk #11 to data/measurements.txt_chunk_11.hdf5\n",
      "Saved chunk #12 to data/measurements.txt_chunk_12.hdf5\n",
      "Saved chunk #13 to data/measurements.txt_chunk_13.hdf5\n",
      "Saved chunk #14 to data/measurements.txt_chunk_14.hdf5\n",
      "Saved chunk #15 to data/measurements.txt_chunk_15.hdf5\n",
      "Saved chunk #16 to data/measurements.txt_chunk_16.hdf5\n",
      "Saved chunk #17 to data/measurements.txt_chunk_17.hdf5\n",
      "Saved chunk #18 to data/measurements.txt_chunk_18.hdf5\n",
      "Saved chunk #19 to data/measurements.txt_chunk_19.hdf5\n",
      "Saved chunk #20 to data/measurements.txt_chunk_20.hdf5\n",
      "Saved chunk #21 to data/measurements.txt_chunk_21.hdf5\n",
      "Saved chunk #22 to data/measurements.txt_chunk_22.hdf5\n",
      "Saved chunk #23 to data/measurements.txt_chunk_23.hdf5\n",
      "Saved chunk #24 to data/measurements.txt_chunk_24.hdf5\n",
      "Saved chunk #25 to data/measurements.txt_chunk_25.hdf5\n",
      "Saved chunk #26 to data/measurements.txt_chunk_26.hdf5\n",
      "Saved chunk #27 to data/measurements.txt_chunk_27.hdf5\n",
      "Saved chunk #28 to data/measurements.txt_chunk_28.hdf5\n",
      "Saved chunk #29 to data/measurements.txt_chunk_29.hdf5\n",
      "Saved chunk #30 to data/measurements.txt_chunk_30.hdf5\n",
      "Saved chunk #31 to data/measurements.txt_chunk_31.hdf5\n",
      "Saved chunk #32 to data/measurements.txt_chunk_32.hdf5\n",
      "Saved chunk #33 to data/measurements.txt_chunk_33.hdf5\n",
      "Saved chunk #34 to data/measurements.txt_chunk_34.hdf5\n",
      "Saved chunk #35 to data/measurements.txt_chunk_35.hdf5\n",
      "Saved chunk #36 to data/measurements.txt_chunk_36.hdf5\n",
      "Saved chunk #37 to data/measurements.txt_chunk_37.hdf5\n",
      "Saved chunk #38 to data/measurements.txt_chunk_38.hdf5\n",
      "Saved chunk #39 to data/measurements.txt_chunk_39.hdf5\n",
      "Saved chunk #40 to data/measurements.txt_chunk_40.hdf5\n",
      "Saved chunk #41 to data/measurements.txt_chunk_41.hdf5\n",
      "Saved chunk #42 to data/measurements.txt_chunk_42.hdf5\n",
      "Saved chunk #43 to data/measurements.txt_chunk_43.hdf5\n",
      "Saved chunk #44 to data/measurements.txt_chunk_44.hdf5\n",
      "Saved chunk #45 to data/measurements.txt_chunk_45.hdf5\n",
      "Saved chunk #46 to data/measurements.txt_chunk_46.hdf5\n",
      "Saved chunk #47 to data/measurements.txt_chunk_47.hdf5\n",
      "Saved chunk #48 to data/measurements.txt_chunk_48.hdf5\n",
      "Saved chunk #49 to data/measurements.txt_chunk_49.hdf5\n",
      "Saved chunk #50 to data/measurements.txt_chunk_50.hdf5\n",
      "Saved chunk #51 to data/measurements.txt_chunk_51.hdf5\n",
      "Saved chunk #52 to data/measurements.txt_chunk_52.hdf5\n",
      "Saved chunk #53 to data/measurements.txt_chunk_53.hdf5\n",
      "Saved chunk #54 to data/measurements.txt_chunk_54.hdf5\n",
      "Saved chunk #55 to data/measurements.txt_chunk_55.hdf5\n",
      "Saved chunk #56 to data/measurements.txt_chunk_56.hdf5\n",
      "Saved chunk #57 to data/measurements.txt_chunk_57.hdf5\n",
      "Saved chunk #58 to data/measurements.txt_chunk_58.hdf5\n",
      "Saved chunk #59 to data/measurements.txt_chunk_59.hdf5\n",
      "Saved chunk #60 to data/measurements.txt_chunk_60.hdf5\n",
      "Saved chunk #61 to data/measurements.txt_chunk_61.hdf5\n",
      "Saved chunk #62 to data/measurements.txt_chunk_62.hdf5\n",
      "Saved chunk #63 to data/measurements.txt_chunk_63.hdf5\n",
      "Saved chunk #64 to data/measurements.txt_chunk_64.hdf5\n",
      "Saved chunk #65 to data/measurements.txt_chunk_65.hdf5\n",
      "Saved chunk #66 to data/measurements.txt_chunk_66.hdf5\n",
      "Saved chunk #67 to data/measurements.txt_chunk_67.hdf5\n",
      "Saved chunk #68 to data/measurements.txt_chunk_68.hdf5\n",
      "Saved chunk #69 to data/measurements.txt_chunk_69.hdf5\n",
      "Saved chunk #70 to data/measurements.txt_chunk_70.hdf5\n",
      "Saved chunk #71 to data/measurements.txt_chunk_71.hdf5\n",
      "Saved chunk #72 to data/measurements.txt_chunk_72.hdf5\n",
      "Saved chunk #73 to data/measurements.txt_chunk_73.hdf5\n",
      "Saved chunk #74 to data/measurements.txt_chunk_74.hdf5\n",
      "Saved chunk #75 to data/measurements.txt_chunk_75.hdf5\n",
      "Saved chunk #76 to data/measurements.txt_chunk_76.hdf5\n",
      "Saved chunk #77 to data/measurements.txt_chunk_77.hdf5\n",
      "Saved chunk #78 to data/measurements.txt_chunk_78.hdf5\n",
      "Saved chunk #79 to data/measurements.txt_chunk_79.hdf5\n",
      "Saved chunk #80 to data/measurements.txt_chunk_80.hdf5\n",
      "Saved chunk #81 to data/measurements.txt_chunk_81.hdf5\n",
      "Saved chunk #82 to data/measurements.txt_chunk_82.hdf5\n",
      "Saved chunk #83 to data/measurements.txt_chunk_83.hdf5\n",
      "Saved chunk #84 to data/measurements.txt_chunk_84.hdf5\n",
      "Saved chunk #85 to data/measurements.txt_chunk_85.hdf5\n",
      "Saved chunk #86 to data/measurements.txt_chunk_86.hdf5\n",
      "Saved chunk #87 to data/measurements.txt_chunk_87.hdf5\n",
      "Saved chunk #88 to data/measurements.txt_chunk_88.hdf5\n",
      "Saved chunk #89 to data/measurements.txt_chunk_89.hdf5\n",
      "Saved chunk #90 to data/measurements.txt_chunk_90.hdf5\n",
      "Saved chunk #91 to data/measurements.txt_chunk_91.hdf5\n",
      "Saved chunk #92 to data/measurements.txt_chunk_92.hdf5\n",
      "Saved chunk #93 to data/measurements.txt_chunk_93.hdf5\n",
      "Saved chunk #94 to data/measurements.txt_chunk_94.hdf5\n",
      "Saved chunk #95 to data/measurements.txt_chunk_95.hdf5\n",
      "Saved chunk #96 to data/measurements.txt_chunk_96.hdf5\n",
      "Saved chunk #97 to data/measurements.txt_chunk_97.hdf5\n",
      "Saved chunk #98 to data/measurements.txt_chunk_98.hdf5\n",
      "Saved chunk #99 to data/measurements.txt_chunk_99.hdf5\n",
      "Converting 100 chunks into single file data/measurements.txt.hdf5\n",
      "export(hdf5) [########################################] 100.00% elapsed time  :   198.26s =  3.3m =  0.1h h                  \n",
      " "
     ]
    }
   ],
   "source": [
    "df = vaex.from_csv('data/measurements.txt', names=['station', 'measure'], sep=';',convert=True,chunk_size=10_000_000 , progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d90ac00-50bd-4bcc-859a-42dd4f285546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_vaex Tempo de processamento:49.093 segundos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                                </th><th>station     </th><th>measure_min  </th><th>measure_max  </th><th>measure_mean         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i>    </td><td>Borgentreich</td><td>-99.9        </td><td>99.9         </td><td>-0.17837456749134986 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i>    </td><td>Falkenberg  </td><td>-99.9        </td><td>99.9         </td><td>-0.15636033723972742 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i>    </td><td>Workington  </td><td>-99.9        </td><td>99.9         </td><td>0.1779083903507457   </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i>    </td><td>Al Wajh     </td><td>-99.9        </td><td>99.9         </td><td>-0.3690835063228942  </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i>    </td><td>Murgap      </td><td>-99.9        </td><td>99.9         </td><td>-0.052552561593657586</td></tr>\n",
       "<tr><td>...                              </td><td>...         </td><td>...          </td><td>...          </td><td>...                  </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>8,831</i></td><td>Tettu       </td><td>-99.9        </td><td>99.9         </td><td>0.3071891767668189   </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>8,832</i></td><td>Belm        </td><td>-99.9        </td><td>99.9         </td><td>-0.21524021476617236 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>8,833</i></td><td>Nyíregyháza </td><td>-99.9        </td><td>99.9         </td><td>-0.13624434888080206 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>8,834</i></td><td>Sherpur     </td><td>-99.9        </td><td>99.9         </td><td>-0.36114642043410505 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>8,835</i></td><td>Anklam      </td><td>-99.9        </td><td>99.9         </td><td>0.24539839468475588  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "#      station       measure_min    measure_max    measure_mean\n",
       "0      Borgentreich  -99.9          99.9           -0.17837456749134986\n",
       "1      Falkenberg    -99.9          99.9           -0.15636033723972742\n",
       "2      Workington    -99.9          99.9           0.1779083903507457\n",
       "3      Al Wajh       -99.9          99.9           -0.3690835063228942\n",
       "4      Murgap        -99.9          99.9           -0.052552561593657586\n",
       "...    ...           ...            ...            ...\n",
       "8,831  Tettu         -99.9          99.9           0.3071891767668189\n",
       "8,832  Belm          -99.9          99.9           -0.21524021476617236\n",
       "8,833  Nyíregyháza   -99.9          99.9           -0.13624434888080206\n",
       "8,834  Sherpur       -99.9          99.9           -0.36114642043410505\n",
       "8,835  Anklam        -99.9          99.9           0.24539839468475588"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timer\n",
    "def test_vaex():\n",
    "    return df.groupby(df['station']).agg({'measure': ['min', 'max', 'mean']})\n",
    "\n",
    "\n",
    "test_vaex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb0c6c-c3a2-4843-8e85-3c7ac77d403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora01\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab018f-e073-4ab4-ba69-6b98813986ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora02\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd8557-34ae-4873-bbd6-02819ea12b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora03\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40fd2e-d5d3-494a-89d0-3e2109f5b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora04\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80890444-09da-4dd7-a4a4-21a3213c53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora05\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc9972-7238-4976-89f5-263dfbcceefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora06\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb553c-e8d9-4050-94bf-ab84dab6537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora07\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f49135-6883-4aae-aa1a-86b22496ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora08\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fca550-56b0-408d-98ae-26b8967ecb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora09\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9e29f-1b68-420f-a9d0-79998bef6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e808a9-c4c1-46d8-b29e-2553caa37d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e1461-caf7-4252-ab8d-ede0f6f6419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98eb77-35ad-4d99-b14b-b918b68c83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b02a0-6493-4c05-b0f8-6250c848cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073b820-4cde-4db7-88e0-1cc81c5d61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da02d5-0cfe-4797-8492-d0ac66400b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d620b-fff8-4510-b55a-dd8bfb84c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0aa1f-81c9-4d88-b98a-f22ebc55a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cdcc91-f8eb-461e-80b5-2db463929d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd813f7d-8ca4-4579-aa6f-081a3b6963e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"ancora20\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
