{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816f246f-6a06-4b4c-9d95-4fa1f75321a0",
   "metadata": {},
   "source": [
    "# Aula 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2560c-bb8d-4c4c-ad8a-f3614d5fbab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a570716-3119-4e7e-9dd8-9730e885cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_13')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5402b65-a752-4627-8573-f922bf90666f",
   "metadata": {},
   "source": [
    "## Desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975521f4-2e4b-42a8-8e9b-97465ab2b053",
   "metadata": {},
   "source": [
    "* **Situação**: Você deseja implementar um novo método além dos formatos csv e txt, uma api está fornecedo novos dados diariamente e deseja juntar esses arquivos que estão no formato json.\n",
    "\n",
    "* **Aqui está o desafio:** adicionar uma nova pasta para os formatos .json, onde será necessário de consolidar tudo isso em um único DataFrame. Essa é a realidade enfrentada por muitos profissionais, desde iniciantes até os mais experientes.\n",
    "\n",
    "* Então, como podemos resolver esse desafio de maneira simples e eficaz, como já usamos classes para garantir que, à medida que o projeto evolui e novos formatos de arquivo são introduzidos, não será necessário começar o projeto do zero.\n",
    "\n",
    "**Possível escopo do projeto:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abd7cf3-61da-4427-bdd7-c70e5a1d1c6e",
   "metadata": {},
   "source": [
    "```mermaid \n",
    "graph TD;\n",
    "    A[main.py] -->|Executa| B[src/lib/classes];\n",
    "    B --> C[Verifica novos arquivos];\n",
    "    C -->|Sim| D[Salva em pastas data];\n",
    "    D -->|txt| E[data.txt];\n",
    "    D -->|csv| F[data.csv];\n",
    "    D -->|json| G[data.json];\n",
    "    E --> H[Consolida em DataFrame];\n",
    "    F --> H;\n",
    "    G --> H;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a802e7-aba5-4098-90dc-87a3ba03b600",
   "metadata": {},
   "source": [
    "### Criar a classe JsonSource.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6652f26f-ed6a-4a5b-af1c-146814ac42ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/lib/classes/JsonSource.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/lib/classes/JsonSource.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from lib.classes.FilesSources import FilesSources\n",
    "\n",
    "class JsonSource(FilesSources):\n",
    "    \"\"\"\n",
    "    Classe para lidar com fontes de dados em formato JSON.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    folder_path : str\n",
    "        O caminho para a pasta que contém os arquivos JSON.\n",
    "    previous_files : list\n",
    "        Uma lista dos arquivos JSON previamente detectados na pasta.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_path(self):\n",
    "        \"\"\"\n",
    "        Cria o caminho da pasta para armazenar os arquivos JSON, se não existir.\n",
    "        \"\"\"\n",
    "        current_directory = os.getcwd()\n",
    "        self.folder_path = os.path.join(current_directory, 'data', 'json_files')\n",
    "        if not os.path.exists(self.folder_path):\n",
    "            os.makedirs(self.folder_path)\n",
    "\n",
    "    def check_for_new_files(self):\n",
    "        \"\"\"\n",
    "        Verifica se há novos arquivos JSON na pasta e atualiza a lista de arquivos anteriores.\n",
    "        \"\"\"\n",
    "        current_files = os.listdir(self.folder_path)\n",
    "        new_files = [file for file in current_files if file not in self.previous_files and file.endswith('.json')]\n",
    "\n",
    "        if new_files:\n",
    "            print(\"Novos arquivos JSON detectados:\", new_files)\n",
    "            # Atualiza a lista de arquivos anteriores\n",
    "            self.previous_files = current_files\n",
    "        else:\n",
    "            print(\"Nenhum novo arquivo JSON detectado.\")\n",
    "            self.get_data()\n",
    "\n",
    "    def read_json_file(self, file_path):\n",
    "        \"\"\"\n",
    "        Lê um arquivo JSON e retorna os dados.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        file_path : str\n",
    "            O caminho para o arquivo JSON.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dict or None\n",
    "            Os dados do arquivo JSON ou None se ocorrer um erro ao acessar o arquivo.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = pd.read_json(f)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(\"Erro ao acessar o JSON:\", e)\n",
    "            return None\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Obtém os dados dos arquivos JSON na pasta especificada.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame\n",
    "            Um DataFrame contendo os dados de todos os arquivos JSON.\n",
    "        \"\"\"\n",
    "        data_frames = []\n",
    "        for file_path in self.previous_files:\n",
    "            if file_path.endswith('.json'):\n",
    "                path = os.path.join(self.folder_path, file_path)\n",
    "                json_data = self.read_json_file(path)\n",
    "                if json_data is not None:\n",
    "                    data_frames.append(json_data)\n",
    "        if data_frames:\n",
    "            combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "            print(combined_data)\n",
    "            return combined_data\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b2ae2-9a17-47a2-adae-4ef79a1bfbff",
   "metadata": {},
   "source": [
    "### Documentação do Script JSON Source\n",
    "\n",
    "#### Introdução\n",
    "\n",
    "Este script Python faz parte de um sistema projetado para lidar com diferentes fontes de dados, especificamente arquivos no formato JSON. Ele verifica regularmente uma pasta especificada em busca de novos arquivos JSON, lê esses arquivos e os armazena em uma estrutura de dados adequada para processamento posterior.\n",
    "\n",
    "#### Estrutura do Script\n",
    "\n",
    "O script consiste em uma classe `JsonSource` que herda de uma classe base `FilesSources`. Ele contém métodos para criar o caminho da pasta de origem, verificar a presença de novos arquivos JSON, ler os arquivos JSON e obter os dados desses arquivos.\n",
    "\n",
    "#### Uso\n",
    "\n",
    "Para utilizar o script, você precisa seguir estas etapas:\n",
    "\n",
    "1. Certifique-se de ter o Python instalado em seu sistema.\n",
    "2. Clone o repositório contendo o código-fonte do projeto.\n",
    "3. Instale as dependências necessárias, caso haja alguma.\n",
    "4. Execute o script Python `JsonSource.py`.\n",
    "\n",
    "Ao ser executado, o script verificará regularmente a pasta especificada em busca de novos arquivos JSON. Se novos arquivos forem encontrados, eles serão lidos e seus dados serão armazenados para processamento adicional.\n",
    "\n",
    "#### Estrutura de Arquivos\n",
    "\n",
    "O script está estruturado da seguinte forma:\n",
    "\n",
    "- `JsonSource.py`: O arquivo principal contendo a implementação da classe `JsonSource`.\n",
    "- `FilesSources.py`: O arquivo contendo a classe base `FilesSources`.\n",
    "- `lib/`: Uma pasta contendo outros arquivos e classes relacionados ao sistema.\n",
    "\n",
    "#### Dependências\n",
    "\n",
    "O script depende das seguintes bibliotecas Python:\n",
    "\n",
    "- `os`: Biblioteca padrão do Python para interação com o sistema operacional.\n",
    "- `json`: Biblioteca padrão do Python para trabalhar com dados JSON.\n",
    "- `FilesSources`: Uma classe base fornecida pelo projeto para lidar com diferentes fontes de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c51424-0966-4005-bf60-ccc5f8f83dd0",
   "metadata": {},
   "source": [
    "## Criando dois exemplos de arquivos do tipo json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "514363ce-e018-4b2a-9747-43a1b40c6365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/json_files/exemplo01.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/json_files/exemplo01.json\n",
    "[\n",
    "    {\"id\": 1, \"name\": \"João\"},\n",
    "    {\"id\": 2, \"name\": \"Maria\"},\n",
    "    {\"id\": 3, \"name\": \"Pedro\"},\n",
    "    {\"id\": 4, \"name\": \"Ana\"},\n",
    "    {\"id\": 5, \"name\": \"Carlos\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "843f0b3a-1d2d-4682-a790-d23b65aba7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/json_files/exemplo02.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/json_files/exemplo02.json\n",
    "[\n",
    "    {\"id\": 11, \"name\": \"Mariana\"},\n",
    "    {\"id\": 12, \"name\": \"José\"},\n",
    "    {\"id\": 13, \"name\": \"Carla\"},\n",
    "    {\"id\": 14, \"name\": \"Lucas\"},\n",
    "    {\"id\": 15, \"name\": \"Camila\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751e7ea-9efd-4244-a88d-dc3b82f574c0",
   "metadata": {},
   "source": [
    "## Executando a pipeline para conferir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed37e3b5-855e-4e9d-bb36-80584ca0c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novos arquivos CSV detectados: ['exemplo1.csv', 'exemplo2.csv']\n",
      "Novos arquivos TXT detectados: ['exemplo2.txt', 'exemplo1.txt']\n",
      "Novos arquivos JSON detectados: ['exemplo01.json', 'exemplo02.json']\n",
      "Nenhum novo arquivo CSV detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3   Carlos\n",
      "3   4      Ana\n",
      "4   5    Pedro\n",
      "5   6    Luiza\n",
      "6   7   Rafael\n",
      "7   8    Laura\n",
      "8   9   Marcos\n",
      "9  10  Juliana\n",
      "Nenhum novo arquivo TXT detectado.\n",
      "Nenhum novo arquivo JSON detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3    Pedro\n",
      "3   4      Ana\n",
      "4   5   Carlos\n",
      "5  11  Mariana\n",
      "6  12     José\n",
      "7  13    Carla\n",
      "8  14    Lucas\n",
      "9  15   Camila\n",
      "Nenhum novo arquivo CSV detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3   Carlos\n",
      "3   4      Ana\n",
      "4   5    Pedro\n",
      "5   6    Luiza\n",
      "6   7   Rafael\n",
      "7   8    Laura\n",
      "8   9   Marcos\n",
      "9  10  Juliana\n",
      "Nenhum novo arquivo TXT detectado.\n",
      "Nenhum novo arquivo JSON detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3    Pedro\n",
      "3   4      Ana\n",
      "4   5   Carlos\n",
      "5  11  Mariana\n",
      "6  12     José\n",
      "7  13    Carla\n",
      "8  14    Lucas\n",
      "9  15   Camila\n",
      "Nenhum novo arquivo CSV detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3   Carlos\n",
      "3   4      Ana\n",
      "4   5    Pedro\n",
      "5   6    Luiza\n",
      "6   7   Rafael\n",
      "7   8    Laura\n",
      "8   9   Marcos\n",
      "9  10  Juliana\n",
      "Nenhum novo arquivo TXT detectado.\n",
      "Nenhum novo arquivo JSON detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3    Pedro\n",
      "3   4      Ana\n",
      "4   5   Carlos\n",
      "5  11  Mariana\n",
      "6  12     José\n",
      "7  13    Carla\n",
      "8  14    Lucas\n",
      "9  15   Camila\n",
      "Nenhum novo arquivo CSV detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3   Carlos\n",
      "3   4      Ana\n",
      "4   5    Pedro\n",
      "5   6    Luiza\n",
      "6   7   Rafael\n",
      "7   8    Laura\n",
      "8   9   Marcos\n",
      "9  10  Juliana\n",
      "Nenhum novo arquivo TXT detectado.\n",
      "Nenhum novo arquivo JSON detectado.\n",
      "   id     name\n",
      "0   1     João\n",
      "1   2    Maria\n",
      "2   3    Pedro\n",
      "3   4      Ana\n",
      "4   5   Carlos\n",
      "5  11  Mariana\n",
      "6  12     José\n",
      "7  13    Carla\n",
      "8  14    Lucas\n",
      "9  15   Camila\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcnok/bootcamps/bootcamp-jornada-de-dados_2024/aula_13/src/__main__.py\", line 31, in <module>\n",
      "    time.sleep(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python src/__main__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c2127-90ac-4a49-9787-70c5a1b03d46",
   "metadata": {},
   "source": [
    "### Conclusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7b6dc-ef7b-4d68-a033-d6a6575d6c55",
   "metadata": {},
   "source": [
    "* Com classes podemos facilmente implementar novos métodos, como neste caso onde foi adicionando uma nova funcionalidade para arquivos do tipo .json, onde agora a pipeline é capaz de verificar 3 pastas, para arquivos do tipo txt, csv e json, onde é feito uma verificação a cada 10 segundos, caso seja adicionado algum novo arquivo de qualquer um dos 3 formatos o script se encarrega de realizar a combinação em um único dataframe para cada tipo de formato garantindo assim que os dados sejam sempre atualizados para tomada de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3ddc7-1a2d-40e9-a7be-a4d59af65b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
